import sys
from pathlib import Path
from typing import Callable

import torch
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# === PATH HANDLING ===
ROOT = Path(__file__).resolve().parents[1]
if str(ROOT) not in sys.path:
    sys.path.insert(0, str(ROOT))

from data_handling import load_measurements_npz, MeasurementDataset


#### SCORING FUNCTION (EMPIRICAL AMPLITUDE ESTIMATOR) ####

class DatasetLogScore:
    """
    Estimates the log-amplitude of a state based on its empirical frequency.
    """
    def __init__(self, samples: torch.Tensor):
        self.device = samples.device
        self.num_qubits = samples.shape[1]

        self.num_states = 2 ** self.num_qubits
        powers = 2 ** torch.arange(self.num_qubits, device=self.device)
        indices = (samples.long() * powers).sum(dim=1)

        counts = torch.bincount(indices, minlength=self.num_states).float()
        self.log_counts = torch.log(counts + 1e-10)
        self._powers = powers

    def __call__(self, states: torch.Tensor) -> torch.Tensor:
        indices = (states.long() * self._powers).sum(dim=1)
        return 0.5 * self.log_counts[indices]


#### RENYI ENTROPY ESTIMATOR (SWAP OPERATOR) ####

def compute_renyi_entropy_from_samples(
        samples: torch.Tensor,
        subsystem_size: int,
        score_fn: Callable[[torch.Tensor], torch.Tensor]
) -> float:
    """
    Computes S2 = -ln(<Swap>) using the replica trick.
    """
    n_samples = samples.shape[0]
    half = n_samples // 2
    if half == 0:
        return 0.0

    batch1 = samples[:half]
    batch2 = samples[half:2 * half]

    # Subsystem B indices: from l to end
    idx_B = torch.arange(subsystem_size, samples.shape[1], device=samples.device)

    log_psi_1 = score_fn(batch1)
    log_psi_2 = score_fn(batch2)

    # Swap subsystem B between replicas
    batch1_swap = batch1.clone()
    batch1_swap[:, idx_B] = batch2[:, idx_B]
    batch2_swap = batch2.clone()
    batch2_swap[:, idx_B] = batch1[:, idx_B]

    log_psi_1_swap = score_fn(batch1_swap)
    log_psi_2_swap = score_fn(batch2_swap)

    log_ratio = (log_psi_1_swap + log_psi_2_swap) - (log_psi_1 + log_psi_2)
    ratios = torch.exp(log_ratio)

    swap_expectation = ratios.mean().item()

    if swap_expectation <= 1e-12:
        return 0.0

    return -np.log(swap_expectation)


#### MAIN EXECUTION ####

if __name__ == "__main__":

    # === CONFIGURATION ===
    chain_length = 16

    # WE ONLY PROCESS THESE DELTAS
    delta_values = [0.5, 1.0, 2.0]

    file_samples = 5_000_000
    eval_samples = 5_000_000

    # Path definitions matching your setup
    meas_dir = Path("measurements")
    # Using the reference file generated by the exact solver script
    ref_file = Path(f"xxz_{chain_length}_entropy_ref.csv")

    print("=== RENYI ENTROPY RECONSTRUCTION FROM DATA =====================")
    print(f"System: {chain_length} spins")
    print(f"Target Deltas: {delta_values}")
    print("================================================================")

    # --- Load reference file first to infer subsystem sizes (l1,...,lK) ---
    if not ref_file.exists():
        print(f"Reference file {ref_file} not found.")
        sys.exit(1)

    ref_df = pd.read_csv(ref_file)

    # Expect columns: delta,l1,l2,...,lK
    l_cols = [c for c in ref_df.columns if c.startswith("l")]
    if not l_cols:
        print("Reference file has no l* columns (expected l1,l2,...).")
        sys.exit(1)

    # Sort l1,l2,... by numeric index
    l_cols = sorted(l_cols, key=lambda s: int(s[1:]))
    l_axis_ref = [int(c[1:]) for c in l_cols]
    max_l = len(l_axis_ref)  # maximum subsystem size in reference

    results_data = {}

    # 1. LOAD DATA AND COMPUTE ENTROPY
    for delta in delta_values:
        print(f"\nProcessing Delta = {delta}...")

        filename = f"xxz_{chain_length}_delta{delta:.2f}_{file_samples}.npz"
        filepath = meas_dir / filename

        if not filepath.exists():
            print(f"  [Error] File not found: {filepath}")
            continue

        ds = MeasurementDataset(
            [filepath],
            load_fn=load_measurements_npz,
            system_param_keys=["delta"],
            samples_per_file=[eval_samples],
        )

        samples = torch.as_tensor(ds.values, dtype=torch.uint8)

        # Sanity Check
        if samples.shape[1] != chain_length:
            print(f"  [Error] Loaded dimensions {samples.shape} do not match chain length {chain_length}")
            continue

        scorer = DatasetLogScore(samples)

        curve = []
        for l in range(1, max_l + 1):
            s2 = compute_renyi_entropy_from_samples(samples, l, scorer)
            curve.append(s2)
            sys.stdout.write(f"\r  l={l}: S2={s2:.4f}")
            sys.stdout.flush()

        results_data[delta] = curve
        print(" -> Done.")

    # 2. PLOTTING (Side-by-Side, Shared Y-Axis)
    print("\nPlotting...")

    # Setup subplots sharing Y axis
    fig, axes = plt.subplots(1, len(delta_values), figsize=(5 * len(delta_values), 5),
                             sharey=True, dpi=100)

    # If len(delta_values) == 1, axes is a single Axes, not an array
    if len(delta_values) == 1:
        axes = [axes]

    styles = {
        0.5: {'color': '#5D8AA8', 'label': r'XY-like ($\Delta=0.5$)'},
        1.0: {'color': '#A0522D', 'label': r'Heisenberg ($\Delta=1.0$)'},
        2.0: {'color': '#556B2F', 'label': r'Néel/Ising ($\Delta=2.0$)'}
    }

    subsystem_axis = l_axis_ref  # [1, 2, ..., max_l]

    for i, delta in enumerate(delta_values):
        ax = axes[i]

        if delta not in results_data:
            ax.set_title(f"$\Delta={delta}$ (No Data)")
            continue

        color = styles[delta]['color']

        # --- Reference curve: pick row with matching delta ---
        mask = np.isclose(ref_df["delta"].values, delta, atol=1e-8)
        if mask.any():
            row = ref_df.loc[mask].iloc[0]
            s2_ref = row[l_cols].to_numpy()

            # Align lengths just in case
            min_len = min(len(subsystem_axis), len(s2_ref), len(results_data[delta]))
            x_vals = subsystem_axis[:min_len]
            y_ref = s2_ref[:min_len]
            y_data = results_data[delta][:min_len]

            ax.plot(
                x_vals,
                y_ref,
                ':',
                color='gray',
                linewidth=2.0,
                label=r'$S_2^{\mathrm{reference}}$',
                zorder=1,
            )
        else:
            # No reference row found for this delta
            min_len = min(len(subsystem_axis), len(results_data[delta]))
            x_vals = subsystem_axis[:min_len]
            y_data = results_data[delta][:min_len]
            y_ref = None

        # --- Data: colored markers on top ---
        if 'y_data' not in locals():
            # define if we skipped above
            min_len = min(len(subsystem_axis), len(results_data[delta]))
            x_vals = subsystem_axis[:min_len]
            y_data = results_data[delta][:min_len]

        ax.plot(
            x_vals,
            y_data,
            'o',
            markersize=8,
            color=color,
            markeredgecolor='black',
            alpha=0.9,
            label=r'$S_2^{\mathrm{data}}$',
            zorder=2,
        )

        # Formatting
        ax.set_title(f"$\Delta = {delta}$", fontsize=14)
        ax.set_xlabel(r"Subsystem size $\ell$", fontsize=12)
        ax.set_xticks(subsystem_axis)
        ax.grid(True, alpha=0.3)

        if i == 0:
            ax.set_ylabel(r"Rényi Entropy $S_2$", fontsize=14)
            ax.legend(loc='lower right', fontsize=10)

        # Clean up temp var for next loop
        if 'y_data' in locals():
            del y_data

    plt.suptitle(f"Entanglement Entropy ($N={chain_length}$)", fontsize=16)
    plt.tight_layout()
    plt.show()
