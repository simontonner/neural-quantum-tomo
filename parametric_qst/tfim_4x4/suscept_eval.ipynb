{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-19T22:56:47.253083Z",
     "start_time": "2026-01-19T22:56:45.603976Z"
    }
   },
   "source": [
    "import sys\n",
    "import math\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append(str(Path(\"..\").resolve()))\n",
    "from hyper_rbm import load_model\n",
    "\n",
    "# Define paths\n",
    "models_dir = Path(\"models\")\n",
    "results_dir = Path(\"results\")\n",
    "results_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "device = \"cpu\"\n",
    "print(f\"Running on: {device}\")\n",
    "print(f\"Looking for models in: {models_dir}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on: cpu\n",
      "Looking for models in: models\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T22:58:28.733390Z",
     "start_time": "2026-01-19T22:58:28.727863Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def estimate_susceptibility(model, h_val, n_samples, k_steps, rng):\n",
    "    dtype = next(model.parameters()).dtype\n",
    "\n",
    "    with torch.no_grad():\n",
    "        cond_batch_gen = torch.full((n_samples, 1), h_val, device=device, dtype=dtype)\n",
    "\n",
    "        schedule_tensor = torch.tensor([1.0] * k_steps, device=device, dtype=dtype)\n",
    "        samples = model.generate(cond_batch_gen, T_schedule=schedule_tensor, rng=rng)\n",
    "\n",
    "    # create a batch of conditioning values for later gradient computation\n",
    "    cond_batch_grad = torch.full((n_samples, 1), h_val, device=device, dtype=dtype, requires_grad=True)\n",
    "\n",
    "    # we evaluate log_score with gradients enabled on cond_batch\n",
    "    log_psi = model.log_score(samples, cond_batch_grad)\n",
    "\n",
    "    # since we parametrized log_psi with cond_batch the Jacobian has only main diagonal terms\n",
    "    grads = torch.autograd.grad(\n",
    "        outputs=log_psi,\n",
    "        inputs=cond_batch_grad,\n",
    "        grad_outputs=torch.ones_like(log_psi), # upstream gradient in VJP (scales each main diag term)\n",
    "        create_graph=False\n",
    "    )[0]\n",
    "\n",
    "    # quadratic formula can be simplified to variance of the gradient (Var(d log_psi / dh))\n",
    "    chi = torch.var(grads.squeeze(), unbiased=True)\n",
    "    return chi.item()"
   ],
   "id": "57f3f5c17a41f4d2",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T22:57:43.746690Z",
     "start_time": "2026-01-19T22:57:43.739567Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_filename = \"hyprbm_tfim_4x4_20000_suscept_20260119_213354.pt\"\n",
    "model_path = models_dir / model_filename\n",
    "\n",
    "print(f\"Loading checkpoint: {model_path.name}\")\n",
    "\n",
    "model, config = load_model(model_path, device)\n",
    "\n",
    "h_support = config.get(\"h_support\", [])\n",
    "SIDE_LENGTH = int(math.sqrt(model.num_v))\n",
    "\n",
    "print(f\"Trained on support points: {h_support} \\n\")\n",
    "\n",
    "ref_file = Path(\"tfim_4x4_suscept_ref.csv\")\n",
    "ref_df = pd.read_csv(ref_file)\n",
    "print(f\"Loaded ED reference data from: {ref_file.name}\")"
   ],
   "id": "ad01a30077cb08ef",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint: hyprbm_tfim_4x4_20000_suscept_20260119_213354.pt\n",
      "Trained on support points: [1.0, 1.1, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5] \n",
      "\n",
      "Loaded ED reference data from: tfim_4x4_suscept_ref.csv\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T23:06:03.277672Z",
     "start_time": "2026-01-19T23:05:22.598058Z"
    }
   },
   "cell_type": "code",
   "source": [
    "H_MIN = 1.0\n",
    "H_MAX = 4.5\n",
    "SWEEP_POINTS = 50\n",
    "SAMPLES_EVAL = 100_000\n",
    "K_STEPS_EVAL = 10\n",
    "\n",
    "h_eval = np.linspace(H_MIN, H_MAX, SWEEP_POINTS)\n",
    "\n",
    "print(f\"Sweeping from h={H_MIN} to h={H_MAX} in {SWEEP_POINTS} steps with {SAMPLES_EVAL} Gibbs samples each...\")\n",
    "\n",
    "chi_values = []\n",
    "for i, h in enumerate(h_eval):\n",
    "\n",
    "    # instead of carrying over RNG state, we have Common Random Numbers (CRN)\n",
    "    rng_point = torch.Generator(device=device).manual_seed(42)\n",
    "\n",
    "    chi = estimate_susceptibility(model, h, n_samples=SAMPLES_EVAL, k_steps=K_STEPS_EVAL, rng=rng_point)\n",
    "    chi_values.append(chi)\n",
    "\n",
    "    if ((i + 1) % 10) == 0:\n",
    "        print(f\"h={h:.2f} | chi={chi:.4f}\")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 5), dpi=200)\n",
    "\n",
    "plt.plot(ref_df[\"h\"], ref_df[\"chi_F\"], \"--\", color=\"gray\", linewidth=2, alpha=0.6, label=\"ED Reference\")\n",
    "plt.plot(h_eval, chi_values, \"o--\", markersize=5, label=\"RBM Estimate\")\n",
    "\n",
    "for h_supp in h_support:\n",
    "    plt.axvline(h_supp, linestyle=\":\", color=\"k\", alpha=0.3)\n",
    "    plt.text(h_supp, 0.03, \"Support\", rotation=90, va=\"bottom\", ha=\"center\",\n",
    "             fontsize=8, alpha=0.6, transform=plt.gca().get_xaxis_transform())\n",
    "\n",
    "plt.xlabel(r\"Transverse Field\", fontsize=12)\n",
    "plt.ylabel(r\"Fidelity Susceptibility\", fontsize=12)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xlim(H_MIN - 0.05, H_MAX + 0.05)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "c406ee55d2fce255",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sweeping from h=1.0 to h=4.5 in 50 steps with 100000 Gibbs samples each...\n",
      "h=1.64 | chi=0.3313\n",
      "h=2.36 | chi=0.7545\n",
      "h=3.07 | chi=0.3422\n",
      "h=3.79 | chi=0.0521\n",
      "h=4.50 | chi=0.0068\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T19:30:14.086893Z",
     "start_time": "2026-01-19T19:30:14.080294Z"
    }
   },
   "cell_type": "code",
   "source": [
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "results = np.column_stack((h_eval, chi_values))\n",
    "\n",
    "file_name = f\"tfim_{SIDE_LENGTH}x{SIDE_LENGTH}_suscept_rbm_{timestamp}.csv\"\n",
    "save_path = results_dir / file_name\n",
    "\n",
    "header = \"h,chi_F\"\n",
    "np.savetxt(save_path, results, delimiter=\",\", header=header, comments=\"\")\n",
    "print(f\"Data saved to: {save_path}\")"
   ],
   "id": "e791eabbd7ef112f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to: results/tfim_4x4_suscept_rbm_20260119_203014.csv\n"
     ]
    }
   ],
   "execution_count": 36
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
