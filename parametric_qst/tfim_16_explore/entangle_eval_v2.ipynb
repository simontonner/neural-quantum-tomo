{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-13T00:56:59.177223Z",
     "start_time": "2026-01-13T00:56:59.168301Z"
    }
   },
   "source": [
    "import sys\n",
    "import math\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.colors as mcolors\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from pathlib import Path\n",
    "\n",
    "# =========================\n",
    "# GLOBAL CONFIG (KEEP HERE)\n",
    "# =========================\n",
    "\n",
    "# CPU only\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# Paths\n",
    "models_dir = Path(\"models\")\n",
    "\n",
    "# Seed\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# \"Deep Yellow\" sigmoid-anneal schedule (same as your working script)\n",
    "ANNEAL_T_START = 5.0\n",
    "ANNEAL_STEPS   = 100\n",
    "ANNEAL_FALLOFF = 0.4\n",
    "T_END          = 1.0\n",
    "\n",
    "# Evaluation / sampling\n",
    "TOTAL_SAMPLES = 100_000\n",
    "CHUNK_SIZE    = 10_000\n",
    "\n",
    "# h-grid\n",
    "DENSE_RES = 0.05\n",
    "\n",
    "print(f\"Running on: {device}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on: cpu\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T00:57:01.398144Z",
     "start_time": "2026-01-13T00:57:01.381155Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Conditioner(nn.Module):\n",
    "    def __init__(self, num_visible: int, num_hidden: int, cond_dim: int, hidden_width: int):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(cond_dim, hidden_width)\n",
    "        self.fc2 = nn.Linear(hidden_width, 2 * (num_visible + num_hidden))\n",
    "        self.num_visible = num_visible\n",
    "        self.num_hidden = num_hidden\n",
    "\n",
    "    def forward(self, cond: torch.Tensor):\n",
    "        x = torch.tanh(self.fc1(cond))\n",
    "        x = self.fc2(x)\n",
    "        return torch.split(\n",
    "            x,\n",
    "            [self.num_visible, self.num_visible, self.num_hidden, self.num_hidden],\n",
    "            dim=-1\n",
    "        )\n",
    "\n",
    "\n",
    "class ConditionalRBM(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            num_visible: int,\n",
    "            num_hidden: int,\n",
    "            cond_dim: int,\n",
    "            conditioner_width: int = 64,\n",
    "            k: int = 1,\n",
    "            T: float = 1.0\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.num_visible = num_visible\n",
    "        self.num_hidden = num_hidden\n",
    "        self.k = k\n",
    "        self.T = T\n",
    "\n",
    "        self.W = nn.Parameter(torch.empty(num_visible, num_hidden))\n",
    "        self.b = nn.Parameter(torch.zeros(num_visible))\n",
    "        self.c = nn.Parameter(torch.zeros(num_hidden))\n",
    "        self.conditioner = Conditioner(num_visible, num_hidden, cond_dim, conditioner_width)\n",
    "\n",
    "        nn.init.normal_(self.W, std=0.01)\n",
    "\n",
    "    def _compute_effective_biases(self, cond: torch.Tensor):\n",
    "        gamma_b, beta_b, gamma_c, beta_c = self.conditioner(cond)\n",
    "        if cond.dim() == 1:\n",
    "            b_mod = (1.0 + gamma_b) * self.b + beta_b\n",
    "            c_mod = (1.0 + gamma_c) * self.c + beta_c\n",
    "        else:\n",
    "            b_mod = (1.0 + gamma_b) * self.b.unsqueeze(0) + beta_b\n",
    "            c_mod = (1.0 + gamma_c) * self.c.unsqueeze(0) + beta_c\n",
    "        return b_mod, c_mod\n",
    "\n",
    "    @staticmethod\n",
    "    def _apply_flip(v: torch.Tensor, s0: torch.Tensor) -> torch.Tensor:\n",
    "        return s0 * v + (1.0 - s0) * (1.0 - v)\n",
    "\n",
    "    def _gibbs_step_sym_fast(self, v, h, s0, b_mod, c_mod, rng):\n",
    "        # 1) sample h | v,s\n",
    "        v_eff = self._apply_flip(v, s0)\n",
    "        p_h = torch.sigmoid((v_eff @ self.W + c_mod) / self.T)\n",
    "        h = torch.bernoulli(p_h, generator=rng)\n",
    "\n",
    "        # 2) sample s | v,h\n",
    "        a = h @ self.W.t()\n",
    "        vb   = (v * b_mod).sum(dim=-1)\n",
    "        va   = (v * a).sum(dim=-1)\n",
    "        bsum = b_mod.sum(dim=-1)\n",
    "        asum = a.sum(dim=-1)\n",
    "        dE = (-bsum - asum + 2.0 * vb + 2.0 * va)\n",
    "        p_s0 = torch.sigmoid(dE / self.T)\n",
    "        s0 = torch.bernoulli(p_s0, generator=rng).to(v.dtype).unsqueeze(-1)\n",
    "\n",
    "        # 3) sample v | h,s\n",
    "        p_v = torch.sigmoid((a + b_mod) / self.T)\n",
    "        v_eff = torch.bernoulli(p_v, generator=rng)\n",
    "        v_next = self._apply_flip(v_eff, s0)\n",
    "        return v_next, h, s0\n",
    "\n",
    "    # --- Free energy / scoring ---\n",
    "    def _free_energies_pair(self, v: torch.Tensor, b_mod: torch.Tensor, c_mod: torch.Tensor):\n",
    "        v = v.to(dtype=self.W.dtype, device=self.W.device)\n",
    "        v_W = v @ self.W\n",
    "        W_sum = self.W.sum(dim=0)\n",
    "\n",
    "        linear_v = v_W + c_mod\n",
    "        linear_f = W_sum.unsqueeze(0) - v_W + c_mod\n",
    "\n",
    "        term2_v = F.softplus(linear_v).sum(dim=-1)\n",
    "        term2_f = F.softplus(linear_f).sum(dim=-1)\n",
    "        term1_v = -(v * b_mod).sum(dim=-1)\n",
    "        term1_f = -((1.0 - v) * b_mod).sum(dim=-1)\n",
    "        return (term1_v - term2_v), (term1_f - term2_f)\n",
    "\n",
    "    def _free_energy(self, v: torch.Tensor, b_mod: torch.Tensor, c_mod: torch.Tensor) -> torch.Tensor:\n",
    "        F_v, F_f = self._free_energies_pair(v, b_mod, c_mod)\n",
    "        stacked = torch.stack([-F_v, -F_f], dim=-1)\n",
    "        return -self.T * torch.logsumexp(stacked / self.T, dim=-1)\n",
    "\n",
    "    def log_score(self, v: torch.Tensor, cond: torch.Tensor) -> torch.Tensor:\n",
    "        b_mod, c_mod = self._compute_effective_biases(cond)\n",
    "        return -0.5 * self._free_energy(v, b_mod, c_mod) / self.T\n",
    "\n",
    "    # --- Sigmoid annealed generation (same as your working script) ---\n",
    "    @torch.no_grad()\n",
    "    def generate_sigmoid(self, cond: torch.Tensor, steps: int, falloff: float, rng: torch.Generator) -> torch.Tensor:\n",
    "        if cond.dim() == 1:\n",
    "            cond = cond.view(-1, 1)\n",
    "        cond = cond.to(self.W.device, dtype=self.W.dtype)\n",
    "\n",
    "        b_mod, c_mod = self._compute_effective_biases(cond)\n",
    "        B = cond.shape[0]\n",
    "\n",
    "        v = torch.bernoulli(\n",
    "            torch.full((B, self.num_visible), 0.5, device=self.W.device, dtype=self.W.dtype),\n",
    "            generator=rng\n",
    "        )\n",
    "        h = torch.zeros((B, self.num_hidden), device=self.W.device, dtype=self.W.dtype)\n",
    "        s0 = torch.ones((B, 1), device=self.W.device, dtype=self.W.dtype)\n",
    "\n",
    "        t_indices = torch.arange(steps, device=self.W.device, dtype=self.W.dtype)\n",
    "        center = steps / 2.0\n",
    "        s = 1.0 / (1.0 + torch.exp(falloff * (t_indices - center)))\n",
    "        temps = T_END + (ANNEAL_T_START - T_END) * s\n",
    "\n",
    "        T_original = float(self.T)\n",
    "        for i in range(steps):\n",
    "            self.T = temps[i]\n",
    "            v, h, s0 = self._gibbs_step_sym_fast(v, h, s0, b_mod, c_mod, rng)\n",
    "\n",
    "        self.T = T_original\n",
    "        return v\n"
   ],
   "id": "7c758960a4c253c4",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T00:57:05.428009Z",
     "start_time": "2026-01-13T00:57:05.414998Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def compute_renyi_large_batch(\n",
    "        samples: torch.Tensor,\n",
    "        subs_size: int,\n",
    "        log_score_fn: callable,\n",
    "        chunk_size: int = 10_000\n",
    ") -> tuple:\n",
    "    n_total = samples.shape[0]\n",
    "    n_chunks = max(1, n_total // chunk_size)\n",
    "    scores = log_score_fn(samples)\n",
    "\n",
    "    chunk_s2_values = []\n",
    "    for i in range(n_chunks):\n",
    "        start = i * chunk_size\n",
    "        end = min((i + 1) * chunk_size, n_total)\n",
    "        if end - start < 2:\n",
    "            continue\n",
    "\n",
    "        c_samples = samples[start:end]\n",
    "        c_scores = scores[start:end]\n",
    "        half = (end - start) // 2\n",
    "        if half < 1:\n",
    "            continue\n",
    "\n",
    "        ref_1 = c_samples[:half]\n",
    "        ref_2 = c_samples[half:2 * half]\n",
    "        ref_1_score = c_scores[:half]\n",
    "        ref_2_score = c_scores[half:2 * half]\n",
    "\n",
    "        slice_idx = torch.arange(subs_size, samples.shape[1], device=samples.device)\n",
    "        swap_1 = ref_1.clone()\n",
    "        swap_1[:, slice_idx] = ref_2[:, slice_idx]\n",
    "        swap_2 = ref_2.clone()\n",
    "        swap_2[:, slice_idx] = ref_1[:, slice_idx]\n",
    "\n",
    "        log_ratios = (log_score_fn(swap_1) + log_score_fn(swap_2)) - (ref_1_score + ref_2_score)\n",
    "        max_val = torch.max(log_ratios)\n",
    "        log_mean = (torch.log(torch.sum(torch.exp(log_ratios - max_val))) + max_val) - math.log(half)\n",
    "        chunk_s2_values.append(-log_mean.item())\n",
    "\n",
    "    vals = np.array(chunk_s2_values)\n",
    "    mean = float(np.mean(vals)) if len(vals) else float(\"nan\")\n",
    "    err = float(np.std(vals, ddof=1) / np.sqrt(len(vals))) if len(vals) > 1 else 0.0\n",
    "    return mean, err\n",
    "\n",
    "\n",
    "def load_latest_model():\n",
    "    search_path = models_dir / \"crbm_tfim_16_*.pt\"\n",
    "    files = glob.glob(str(search_path))\n",
    "    if not files:\n",
    "        raise FileNotFoundError(\"No models found!\")\n",
    "\n",
    "    latest_file = max(files, key=os.path.getctime)\n",
    "    print(f\"Loading latest model: {latest_file}\")\n",
    "\n",
    "    checkpoint = torch.load(latest_file, map_location=device)\n",
    "    cfg = checkpoint.get(\"config\", {})\n",
    "\n",
    "    model = ConditionalRBM(\n",
    "        num_visible=cfg.get(\"num_visible\", 16),\n",
    "        num_hidden=cfg.get(\"num_hidden\", 64),\n",
    "        cond_dim=1,\n",
    "        conditioner_width=64,\n",
    "        k=cfg.get(\"k_steps\", 20),\n",
    "        T=1.0\n",
    "    ).to(device)\n",
    "\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    model.eval()\n",
    "    return model, cfg\n",
    "\n",
    "\n",
    "model, config = load_latest_model()\n",
    "CHAIN_LENGTH = model.num_visible\n",
    "h_support_vals = sorted(config.get(\"h_support\", [0.5, 0.8, 0.95, 1.0, 1.05, 1.2, 1.5]))\n",
    "print(f\"Loaded L={CHAIN_LENGTH}. Support: {h_support_vals}\")\n"
   ],
   "id": "997a3820fc3d74b4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading latest model: models/crbm_tfim_16_20000_entropy_20260112_192510.pt\n",
      "Loaded L=16. Support: [0.5, 0.8, 0.95, 1.0, 1.05, 1.2, 1.5]\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T00:59:36.868331Z",
     "start_time": "2026-01-13T00:57:08.422036Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Grid setup\n",
    "h_novel_vals = np.arange(min(h_support_vals), max(h_support_vals) + 0.01, DENSE_RES)\n",
    "h_novel_vals = [h for h in h_novel_vals if not any(np.isclose(h, s, atol=1e-3) for s in h_support_vals)]\n",
    "all_h_values = sorted(list(set(h_support_vals) | set(h_novel_vals)))\n",
    "\n",
    "results_list = []\n",
    "l_axis = list(range(1, CHAIN_LENGTH // 2 + 1))\n",
    "\n",
    "rng_eval = torch.Generator(device=\"cpu\").manual_seed(SEED)\n",
    "model_dtype = next(model.parameters()).dtype\n",
    "\n",
    "print(f\"\\n=== Running Final Paper Evaluation ===\")\n",
    "print(f\"Schedule: T={ANNEAL_T_START}->{T_END} | Steps={ANNEAL_STEPS} | falloff={ANNEAL_FALLOFF}\")\n",
    "print(f\"TOTAL_SAMPLES={TOTAL_SAMPLES} | CHUNK_SIZE={CHUNK_SIZE}\")\n",
    "\n",
    "for i, h_val in enumerate(all_h_values):\n",
    "    pt_type = \"support\" if any(np.isclose(h_val, s, atol=1e-3) for s in h_support_vals) else \"interpolated\"\n",
    "\n",
    "    # 1) Generate with sigmoid anneal\n",
    "    cond_gen = torch.tensor([[h_val]], device=device, dtype=model_dtype).expand(TOTAL_SAMPLES, -1)\n",
    "    with torch.no_grad():\n",
    "        samples = model.generate_sigmoid(cond_gen, ANNEAL_STEPS, ANNEAL_FALLOFF, rng_eval)\n",
    "\n",
    "    # 2) Score closure\n",
    "    cond_score = torch.tensor([[h_val]], device=device, dtype=model_dtype)\n",
    "    scorer = lambda v: model.log_score(v, cond_score)\n",
    "\n",
    "    # 3) Renyi S2\n",
    "    for l in l_axis:\n",
    "        s2_mean, s2_err = compute_renyi_large_batch(samples, l, scorer, chunk_size=CHUNK_SIZE)\n",
    "        results_list.append({\"h\": float(h_val), \"l\": int(l), \"s2\": s2_mean, \"s2_err\": s2_err, \"type\": pt_type})\n",
    "\n",
    "    if (i + 1) % 5 == 0 or (i + 1) == len(all_h_values):\n",
    "        print(f\"[{i+1}/{len(all_h_values)}] h={h_val:.2f} done.\")\n",
    "\n",
    "df_res = pd.DataFrame(results_list)\n",
    "print(\"Done.\")\n"
   ],
   "id": "dc5ef14391fd9c40",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running Final Paper Evaluation ===\n",
      "Schedule: T=5.0->1.0 | Steps=100 | falloff=0.4\n",
      "TOTAL_SAMPLES=100000 | CHUNK_SIZE=10000\n",
      "[5/21] h=0.70 done.\n",
      "[10/21] h=0.95 done.\n",
      "[15/21] h=1.20 done.\n",
      "[20/21] h=1.45 done.\n",
      "[21/21] h=1.50 done.\n",
      "Done.\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T01:10:22.266464Z",
     "start_time": "2026-01-13T01:10:22.225518Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# CONFIGURATION (plot only)\n",
    "PLOT_WSPACE = -0.15\n",
    "VERTICAL_OFFSET_2D = 0.02\n",
    "BOX_ASPECT_2D = 0.7\n",
    "Z_LABEL_PAD = 9\n",
    "TITLE_PAD_2D = 20\n",
    "LEGEND_NCOL = 4\n",
    "LEGEND_X = 0.5\n",
    "LEGEND_Y = -0.18\n",
    "\n",
    "pivot_df = df_res.pivot(index='l', columns='h', values='s2')\n",
    "h_dense = pivot_df.columns.values\n",
    "l_values = pivot_df.index.values\n",
    "X_h, Y_l = np.meshgrid(h_dense, l_values)\n",
    "Z_s2 = pivot_df.values\n",
    "\n",
    "support_h_keys = sorted(df_res[df_res['type'] == 'support']['h'].unique())\n",
    "\n",
    "fig = plt.figure(figsize=(16, 6), dpi=150)\n",
    "fig.patch.set_facecolor('white')\n",
    "gs = gridspec.GridSpec(1, 2, width_ratios=[1.6, 0.8], wspace=PLOT_WSPACE)\n",
    "\n",
    "# --- 3D ---\n",
    "ax3d = fig.add_subplot(gs[0], projection='3d')\n",
    "ax3d.set_proj_type('ortho')\n",
    "\n",
    "cmap_surface = plt.get_cmap('viridis')\n",
    "norm = mcolors.Normalize(vmin=h_dense.min(), vmax=h_dense.max())\n",
    "surf = ax3d.plot_surface(\n",
    "    X_h, Y_l, Z_s2,\n",
    "    facecolors=cmap_surface(norm(X_h)),\n",
    "    rstride=1, cstride=1, shade=True, linewidth=0, alpha=0.85\n",
    ")\n",
    "ax3d.set_zlim(np.nanmin(Z_s2) - 0.05, np.nanmax(Z_s2) + 0.1)\n",
    "\n",
    "ax3d.set_xlabel(\"Transverse field $h$\", fontsize=12, labelpad=10)\n",
    "ax3d.set_ylabel(\"Subsystem size $\\\\ell$\", fontsize=12, labelpad=10)\n",
    "ax3d.set_zlabel(\"Rényi entropy $S_2$\", fontsize=12, labelpad=Z_LABEL_PAD)\n",
    "ax3d.view_init(elev=30, azim=-40)\n",
    "\n",
    "# Add lines on 3D (support h)\n",
    "for h in support_h_keys:\n",
    "    subset = df_res[df_res['h'] == h].sort_values('l')\n",
    "    ax3d.plot(\n",
    "        np.full_like(l_values, h, dtype=float),\n",
    "        l_values,\n",
    "        subset['s2'].values,\n",
    "        color='black', linestyle='--', linewidth=0.8, alpha=0.6, zorder=10\n",
    "    )\n",
    "\n",
    "# --- 2D ---\n",
    "ax2d = fig.add_subplot(gs[1])\n",
    "ax2d.set_box_aspect(BOX_ASPECT_2D)\n",
    "pos = ax2d.get_position()\n",
    "ax2d.set_position([pos.x0, pos.y0 + VERTICAL_OFFSET_2D, pos.width, pos.height])\n",
    "\n",
    "cmap_2d = plt.get_cmap(\"tab10\")\n",
    "\n",
    "# Load ED ref (optional)\n",
    "ref_df = None\n",
    "try:\n",
    "    ref_file = Path(f\"tfim_{CHAIN_LENGTH}_entropy_ref.csv\")\n",
    "    if ref_file.exists():\n",
    "        ref_df = pd.read_csv(ref_file)\n",
    "except Exception:\n",
    "    ref_df = None\n",
    "\n",
    "ref_lbl_added = False\n",
    "\n",
    "for i, h in enumerate(support_h_keys):\n",
    "    subset = df_res[df_res['h'] == h].sort_values('l')\n",
    "    s2 = subset['s2'].values\n",
    "    err = subset['s2_err'].values\n",
    "    col = cmap_2d(i % 10)\n",
    "\n",
    "    # ED ref\n",
    "    if ref_df is not None:\n",
    "        mask = np.isclose(ref_df[\"h\"], h, atol=1e-3)\n",
    "        if mask.any():\n",
    "            l_cols = sorted(\n",
    "                [c for c in ref_df.columns if c.startswith(\"l\") and int(c[1:]) in l_values],\n",
    "                key=lambda s: int(s[1:])\n",
    "            )\n",
    "            y_ref = ref_df.loc[mask].iloc[0][l_cols].values\n",
    "            x_ref = [int(c[1:]) for c in l_cols]\n",
    "            lbl = \"ED Reference\" if not ref_lbl_added else \"_nolegend_\"\n",
    "            ax2d.plot(x_ref, y_ref, '--', color='#444444', linewidth=1.2, label=lbl, zorder=5)\n",
    "            ref_lbl_added = True\n",
    "\n",
    "    ax2d.plot(\n",
    "        l_values, s2, 'o-',\n",
    "        color=col, markersize=5, linewidth=1.5, alpha=0.9,\n",
    "        markeredgecolor='white', markeredgewidth=0.5,\n",
    "        label=f\"h={h:.2f}\", zorder=4\n",
    "    )\n",
    "    ax2d.fill_between(l_values, s2 - err, s2 + err, color=col, alpha=0.2, linewidth=0)\n",
    "\n",
    "ax2d.set_xlabel(\"Subsystem size $\\\\ell$\")\n",
    "ax2d.set_title(f\"TFIM L{CHAIN_LENGTH} - Rényi entropy $S_2$\", pad=TITLE_PAD_2D)\n",
    "ax2d.legend(frameon=True, fontsize=9, loc='upper center', bbox_to_anchor=(LEGEND_X, LEGEND_Y), ncol=LEGEND_NCOL)\n",
    "ax2d.grid(True, alpha=0.3)\n",
    "\n",
    "plt.show()"
   ],
   "id": "49e2eee0c799654c",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_res' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 11\u001B[0m\n\u001B[1;32m      8\u001B[0m LEGEND_X \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.5\u001B[39m\n\u001B[1;32m      9\u001B[0m LEGEND_Y \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m0.18\u001B[39m\n\u001B[0;32m---> 11\u001B[0m pivot_df \u001B[38;5;241m=\u001B[39m \u001B[43mdf_res\u001B[49m\u001B[38;5;241m.\u001B[39mpivot(index\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124ml\u001B[39m\u001B[38;5;124m'\u001B[39m, columns\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mh\u001B[39m\u001B[38;5;124m'\u001B[39m, values\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124ms2\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     12\u001B[0m h_dense \u001B[38;5;241m=\u001B[39m pivot_df\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mvalues\n\u001B[1;32m     13\u001B[0m l_values \u001B[38;5;241m=\u001B[39m pivot_df\u001B[38;5;241m.\u001B[39mindex\u001B[38;5;241m.\u001B[39mvalues\n",
      "\u001B[0;31mNameError\u001B[0m: name 'df_res' is not defined"
     ]
    }
   ],
   "execution_count": 2
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
