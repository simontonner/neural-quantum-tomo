{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T23:37:40.624942Z",
     "start_time": "2025-03-27T23:37:39.887903Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import flax.linen as nn\n",
    "import optax\n",
    "from flax.training import train_state\n",
    "\n",
    "from load_mnist import download_mnist_if_needed, load_images, load_labels\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "data_dir = \"./data\"\n",
    "device = jax.devices('cpu')[0]\n",
    "\n",
    "print(f\"Data resides in        : {data_dir}\")\n",
    "print(f\"Training model on      : {str(device)}\")"
   ],
   "id": "27c3d547f23b4972",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data resides in        : ./data\n",
      "Training model on      : TFRT_CPU_0\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T23:37:45.952719Z",
     "start_time": "2025-03-27T23:37:45.433784Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def print_samples(samples, elements_per_row=10, fig_width=10, cmap=\"binary\"):\n",
    "    num_digits = len(samples)\n",
    "    num_rows = (num_digits + elements_per_row - 1) // elements_per_row\n",
    "\n",
    "    plt.figure(figsize=(fig_width, fig_width / elements_per_row * num_rows))\n",
    "    for idx, (label, image) in enumerate(samples):\n",
    "        plt.subplot(num_rows, elements_per_row, idx + 1)\n",
    "        plt.imshow(image.squeeze(), cmap=cmap)\n",
    "        plt.title(label, fontsize=12)\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def preprocess(x):\n",
    "    x = x.astype(np.float32) / 255.0    # normalize to [0, 1]\n",
    "    x = x > 0.5                         # binarize\n",
    "    x = x.reshape(x.shape[0], -1)       # flatten for RBM\n",
    "    x = jnp.array(x, dtype=jnp.float32) # use jax numpy array of dtype float32, because RBM has float32 params\n",
    "    return x\n",
    "\n",
    "\n",
    "data_paths = download_mnist_if_needed(root=data_dir, train_only=True)\n",
    "x_train_raw = load_images(data_paths['train_images'])\n",
    "y_train = load_labels(data_paths['train_labels'])\n",
    "\n",
    "x_train = preprocess(x_train_raw)\n",
    "print(f\"x_train dtype: {x_train.dtype}, shape: {x_train.shape}\")\n",
    "print(f\"x_train min: {x_train.min()}, max: {x_train.max()}\")"
   ],
   "id": "dc789a9d880e97c0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train dtype: float32, shape: (60000, 784)\n",
      "x_train min: 0.0, max: 1.0\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T19:48:39.644129Z",
     "start_time": "2025-03-27T19:48:39.634536Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# === MODIFIED RBM CLASS ===\n",
    "class RBM(nn.Module):\n",
    "    n_visible: int\n",
    "    n_hidden: int\n",
    "\n",
    "    def setup(self):\n",
    "        # Using the initializer from the original request\n",
    "        w_init = nn.initializers.normal(0.01)\n",
    "        self.W = self.param(\"W\", w_init, (self.n_visible, self.n_hidden))\n",
    "        self.b = self.param(\"b\", nn.initializers.zeros, (self.n_visible,))\n",
    "        self.c = self.param(\"c\", nn.initializers.zeros, (self.n_hidden,))\n",
    "\n",
    "    def _sample_hidden(self, v, T=1.0):\n",
    "        # *** Requires 'sample' RNG ***\n",
    "        key = self.make_rng(\"sample\")\n",
    "        logits = (v @ self.W + self.c) / T\n",
    "        h_probs = jax.nn.sigmoid(logits)\n",
    "        h_sample = jax.random.bernoulli(key, h_probs)\n",
    "        # Ensure float32 output for consistency in calculations\n",
    "        return h_sample.astype(jnp.float32), h_probs\n",
    "\n",
    "    def _sample_visible(self, h, T=1.0):\n",
    "        # *** Requires 'sample' RNG ***\n",
    "        key = self.make_rng(\"sample\")\n",
    "        logits = (h @ self.W.T + self.b) / T\n",
    "        v_probs = jax.nn.sigmoid(logits)\n",
    "        v_sample = jax.random.bernoulli(key, v_probs)\n",
    "        # Ensure float32 output\n",
    "        return v_sample.astype(jnp.float32), v_probs\n",
    "\n",
    "    def sample_gibbs(self, v0_sample, k=1, T=1.0):\n",
    "        # This method relies on _sample_hidden/_sample_visible using make_rng.\n",
    "        # The caller (model.apply) must provide the 'sample' RNG.\n",
    "        v = v0_sample\n",
    "        for _ in range(k):\n",
    "            # The internal calls get the RNG via make_rng from the apply context\n",
    "            h, _ = self._sample_hidden(v, T)\n",
    "            v, _ = self._sample_visible(h, T)\n",
    "        return v\n",
    "\n",
    "    def free_energy(self, v):\n",
    "        # Calculate free energy (per sample) - does not require RNG\n",
    "        # Ensure v has a batch dimension\n",
    "        if v.ndim == 1:\n",
    "            v = v[None, :] # Add batch dimension if single sample\n",
    "        visible_term = jnp.dot(v, self.b) # shape: (batch,)\n",
    "        hidden_logits = v @ self.W + self.c # shape: (batch, n_hidden)\n",
    "        # Use jax.nn.softplus for numerical stability: log(1 + exp(x))\n",
    "        hidden_term = jnp.sum(jax.nn.softplus(hidden_logits), axis=-1) # shape: (batch,)\n",
    "        # Return free energy per sample\n",
    "        return -visible_term - hidden_term # shape: (batch,)\n",
    "\n",
    "    def __call__(self, v):\n",
    "        # Flax modules require __call__.\n",
    "        # Returning hidden probabilities requires the 'sample' RNG for _sample_hidden.\n",
    "        # If you only ever call specific methods like free_energy or sample_gibbs\n",
    "        # via model.apply(..., method=...), this __call__ might not be used directly.\n",
    "        # Let's make it return hidden probabilities as a potentially useful default.\n",
    "        # *** If called directly, it needs the 'sample' RNG supplied in rngs={'sample': key} ***\n",
    "        _, h_probs = self._sample_hidden(v)\n",
    "        return h_probs\n",
    "        # Alternative simple __call__ that doesn't need RNG:\n",
    "        # return v"
   ],
   "id": "27fcfc9297da4acd",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T19:55:10.391720Z",
     "start_time": "2025-03-27T19:55:10.380914Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.lax # Make sure lax is imported\n",
    "import flax.linen as nn\n",
    "\n",
    "class RBM(nn.Module):\n",
    "    n_visible: int\n",
    "    n_hidden: int\n",
    "\n",
    "    def setup(self):\n",
    "        w_init = nn.initializers.normal(0.01)\n",
    "        self.W = self.param(\"W\", w_init, (self.n_visible, self.n_hidden))\n",
    "        self.b = self.param(\"b\", nn.initializers.zeros, (self.n_visible,))\n",
    "        self.c = self.param(\"c\", nn.initializers.zeros, (self.n_hidden,))\n",
    "\n",
    "    # === MODIFIED: Accept key explicitly ===\n",
    "    def _sample_hidden(self, key: jax.random.PRNGKey, v, T=1.0):\n",
    "        logits = (v @ self.W + self.c) / T\n",
    "        h_probs = jax.nn.sigmoid(logits)\n",
    "        h_sample = jax.random.bernoulli(key, h_probs)\n",
    "        return h_sample.astype(jnp.float32), h_probs\n",
    "\n",
    "    # === MODIFIED: Accept key explicitly ===\n",
    "    def _sample_visible(self, key: jax.random.PRNGKey, h, T=1.0):\n",
    "        logits = (h @ self.W.T + self.b) / T\n",
    "        v_probs = jax.nn.sigmoid(logits)\n",
    "        v_sample = jax.random.bernoulli(key, v_probs)\n",
    "        return v_sample.astype(jnp.float32), v_probs\n",
    "\n",
    "    # === MODIFIED: Explicit RNG key handling in fori_loop ===\n",
    "    def sample_gibbs(self, v0_sample, k=1, T=1.0):\n",
    "        \"\"\"Performs k steps of Gibbs sampling with explicit RNG handling, JIT compatible.\"\"\"\n",
    "\n",
    "        # Get the initial RNG key from the 'sample' stream provided by model.apply\n",
    "        # This is the ONLY place we use make_rng now for this method's logic.\n",
    "        loop_key = self.make_rng(\"sample\")\n",
    "\n",
    "        def gibbs_step_body(i, carry):\n",
    "            v_carry, key_carry = carry\n",
    "            # Split key for this iteration\n",
    "            key_carry, hidden_key, visible_key = jax.random.split(key_carry, 3)\n",
    "\n",
    "            # Pass keys explicitly\n",
    "            h, _ = self._sample_hidden(hidden_key, v_carry, T)\n",
    "            v_next, _ = self._sample_visible(visible_key, h, T)\n",
    "\n",
    "            # Return updated state (v_next) and the *remaining* part of the key\n",
    "            return (v_next, key_carry)\n",
    "\n",
    "        # Initial carry for the loop: (initial visible state, initial loop key)\n",
    "        initial_carry = (v0_sample, loop_key)\n",
    "\n",
    "        # Run the loop\n",
    "        final_carry = jax.lax.fori_loop(0, k, gibbs_step_body, initial_carry)\n",
    "\n",
    "        # Return only the final visible state from the carry\n",
    "        final_v = final_carry[0]\n",
    "        return final_v\n",
    "    # === END MODIFICATION ===\n",
    "\n",
    "    def free_energy(self, v):\n",
    "        if v.ndim == 1:\n",
    "            v = v[None, :]\n",
    "        visible_term = jnp.dot(v, self.b)\n",
    "        hidden_logits = v @ self.W + self.c\n",
    "        hidden_term = jnp.sum(jax.nn.softplus(hidden_logits), axis=-1)\n",
    "        return -visible_term - hidden_term\n",
    "\n",
    "    # === MODIFIED: Needs key if called directly, uses _sample_hidden ===\n",
    "    def __call__(self, v):\n",
    "        # If __call__ is used, it now also needs the 'sample' RNG key\n",
    "        # to pass to _sample_hidden.\n",
    "        key = self.make_rng(\"sample\")\n",
    "        h_sample, h_probs = self._sample_hidden(key, v) # Pass key explicitly\n",
    "        return h_probs # Returning probs might be more useful than samples here\n",
    "        # Or, if you don't want __call__ to require RNG:\n",
    "        # return v # Simplest option"
   ],
   "id": "3d8fb14ccceb3134",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T19:55:12.864992Z",
     "start_time": "2025-03-27T19:55:12.854278Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# === TRAINING CODE ===\n",
    "\n",
    "# Define TrainState - simple wrapper around flax's TrainState\n",
    "class TrainState(train_state.TrainState):\n",
    "    # No additional fields needed for this basic setup\n",
    "    pass\n",
    "\n",
    "# Define the loss function (Contrastive Divergence using PCD)\n",
    "def contrastive_divergence_loss(params, model_apply_fn, v_data, v_fantasy, k, rng_key, T=1.0):\n",
    "    \"\"\"Calculates the PCD loss and the next fantasy particles.\"\"\"\n",
    "    # 1. Generate k-step Gibbs samples starting from fantasy particles\n",
    "    #    Pass the specific model method and the required 'sample' RNG\n",
    "    v_k = model_apply_fn(\n",
    "        {'params': params},\n",
    "        v_fantasy,\n",
    "        k=k,\n",
    "        T=T,\n",
    "        method=RBM.sample_gibbs, # Use the specific method\n",
    "        rngs={'sample': rng_key} # Provide the RNG key for sampling\n",
    "    )\n",
    "\n",
    "    # 2. Calculate free energies (no RNG needed for free_energy)\n",
    "    fe_data = model_apply_fn({'params': params}, v_data, method=RBM.free_energy)\n",
    "    fe_fantasy_k = model_apply_fn({'params': params}, v_k, method=RBM.free_energy)\n",
    "\n",
    "    # 3. Calculate the CD loss (mean over batch)\n",
    "    loss = jnp.mean(fe_data) - jnp.mean(fe_fantasy_k)\n",
    "\n",
    "    # 4. Return loss and the *next* fantasy particles (stop gradient flow)\n",
    "    return loss, jax.lax.stop_gradient(v_k)\n",
    "\n",
    "# Define the JIT-compiled training step\n",
    "@jax.jit\n",
    "def train_step(state, batch, fantasy_particles, k, rng_key, pcd_reset_key, batch_idx, pcd_reset_interval, T=1.0):\n",
    "    \"\"\"Performs a single training step, JIT-compiled.\"\"\"\n",
    "\n",
    "    # 1. Handle Persistent Contrastive Divergence (PCD) reset conditionally\n",
    "    def reset_particles(_): # Function if reset is needed\n",
    "        # Use pcd_reset_key for deterministic reset based on key\n",
    "        return jax.random.bernoulli(pcd_reset_key, p=0.5, shape=fantasy_particles.shape).astype(jnp.float32)\n",
    "\n",
    "    def keep_particles(fp): # Function if no reset needed\n",
    "        return fp\n",
    "\n",
    "    # Conditionally select whether to reset particles based on batch index\n",
    "    current_fantasy_particles = jax.lax.cond(\n",
    "        batch_idx % pcd_reset_interval == 0,\n",
    "        reset_particles, # fun_true: uses pcd_reset_key\n",
    "        keep_particles,  # fun_false: uses existing fantasy_particles\n",
    "        fantasy_particles # operand passed to the selected function\n",
    "    )\n",
    "\n",
    "    # 2. Split RNG key for use in this step and for the next step\n",
    "    step_rng, next_rng = jax.random.split(rng_key)\n",
    "    # Further split step_rng for Gibbs sampling within the loss function\n",
    "    gibbs_rng = step_rng # Use the main step_rng for Gibbs\n",
    "\n",
    "    # 3. Define the loss function for JAX's grad function\n",
    "    #    Captures variables like k, T, model apply_fn from the outer scope.\n",
    "    def loss_fn(params):\n",
    "        # Calculate loss and get the next fantasy particles as auxiliary output\n",
    "        loss, next_fantasy = contrastive_divergence_loss(\n",
    "            params,\n",
    "            state.apply_fn, # The model's apply function\n",
    "            batch,\n",
    "            current_fantasy_particles,\n",
    "            k,\n",
    "            gibbs_rng, # Pass the specific RNG key for Gibbs\n",
    "            T\n",
    "        )\n",
    "        return loss, next_fantasy\n",
    "\n",
    "    # 4. Compute gradients, loss, and auxiliary output (next fantasy particles)\n",
    "    (loss, next_fantasy_particles), grads = jax.value_and_grad(loss_fn, has_aux=True)(state.params)\n",
    "\n",
    "    # 5. Apply gradient updates to the state (includes optimizer step)\n",
    "    state = state.apply_gradients(grads=grads)\n",
    "\n",
    "    # 6. Prepare metrics for logging\n",
    "    metrics = {'loss': loss}\n",
    "\n",
    "    # 7. Return updated state, new fantasy particles, the RNG key for the *next* step, and metrics\n",
    "    return state, next_fantasy_particles, next_rng, metrics"
   ],
   "id": "d07f7b7585a3dfe9",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T19:56:43.518439Z",
     "start_time": "2025-03-27T19:55:14.306921Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "\n",
    "#### TRAINING SETUP ####\n",
    "\n",
    "# Hyperparameters (matching PyTorch setup)\n",
    "batch_size      = 128\n",
    "visible_units   = 28*28 # 784\n",
    "hidden_units    = 256\n",
    "k               = 1      # Gibbs steps for PCD\n",
    "lr              = 1e-3\n",
    "num_epochs      = 40\n",
    "pcd_reset       = 75     # Reset persistent chain every N batches\n",
    "weight_decay    = 1e-5   # L2 regularization\n",
    "lr_decay_rate   = 0.95   # Learning rate decay factor PER EPOCH\n",
    "temperature     = 1.0    # Sampling temperature (fixed)\n",
    "\n",
    "# Calculate steps per epoch and total steps\n",
    "steps_per_epoch = len(x_train) // batch_size\n",
    "total_steps     = num_epochs * steps_per_epoch\n",
    "print(f\"Total training steps: {total_steps}\")\n",
    "\n",
    "# RNG Key Management\n",
    "seed = 0\n",
    "key = jax.random.PRNGKey(seed)\n",
    "# Split key for model initialization, training loop, data shuffling, and PCD init\n",
    "model_key, train_key, data_key, pcd_init_key = jax.random.split(key, 4)\n",
    "\n",
    "# Initialize RBM Model\n",
    "rbm_model = RBM(n_visible=visible_units, n_hidden=hidden_units)\n",
    "# Create dummy input for parameter initialization\n",
    "dummy_input = jnp.zeros((1, visible_units))\n",
    "\n",
    "# --- CORRECTED INITIALIZATION (AGAIN) ---\n",
    "# Provide RNG keys for BOTH 'params' (for initializers) and 'sample' (if __call__ uses it)\n",
    "params = rbm_model.init({'params': model_key, 'sample': model_key}, dummy_input)['params']\n",
    "\n",
    "# Create Optimizer with Learning Rate Schedule and Weight Decay\n",
    "# Exponential decay schedule applied once per epoch\n",
    "lr_schedule = optax.exponential_decay(\n",
    "    init_value=lr,\n",
    "    transition_steps=steps_per_epoch, # Number of steps before decay applied\n",
    "    decay_rate=lr_decay_rate,\n",
    "    staircase=True # Apply decay discretely at the transition steps\n",
    ")\n",
    "\n",
    "# AdamW optimizer (handles weight decay correctly compared to standard Adam)\n",
    "optimizer = optax.adamw(learning_rate=lr_schedule, weight_decay=weight_decay)\n",
    "\n",
    "# Create the Training State\n",
    "tx_state = TrainState.create(apply_fn=rbm_model.apply, params=params, tx=optimizer)\n",
    "\n",
    "# Initialize Fantasy Particles (Persistent Chain for PCD)\n",
    "# Use a dedicated RNG key for initial particles\n",
    "fantasy_particles = jax.random.bernoulli(pcd_init_key, p=0.5, shape=(batch_size, visible_units)).astype(jnp.float32)\n",
    "\n",
    "# Simple NumPy/JAX Data Loader Function\n",
    "def numpy_loader(rng_key, data, batch_size, drop_last=True):\n",
    "    \"\"\"Yields batches of data from a numpy/JAX array with shuffling.\"\"\"\n",
    "    n_data = data.shape[0]\n",
    "    if drop_last:\n",
    "        n_batches = n_data // batch_size\n",
    "    else:\n",
    "        n_batches = -(-n_data // batch_size) # Ceiling division\n",
    "\n",
    "    # Generate a random permutation for shuffling\n",
    "    perm = jax.random.permutation(rng_key, n_data)\n",
    "    # Ensure indices stay within bounds after potential drop_last\n",
    "    perm = perm[:n_batches * batch_size]\n",
    "    perm = perm.reshape((n_batches, batch_size)) # Reshape for easy batch slicing\n",
    "\n",
    "    for indices in perm:\n",
    "        yield data[indices]\n",
    "\n",
    "\n",
    "#### TRAINING LOOP ####\n",
    "\n",
    "print(\"Starting RBM training...\")\n",
    "metrics_history = {'loss': []}\n",
    "\n",
    "# Loop over epochs\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_start_time = time.time()\n",
    "    total_epoch_loss = 0.0\n",
    "\n",
    "    # Get a new key for data shuffling this epoch\n",
    "    data_key, epoch_data_key = jax.random.split(data_key)\n",
    "    # Create batch generator for the current epoch\n",
    "    batch_generator = numpy_loader(epoch_data_key, x_train, batch_size, drop_last=True)\n",
    "\n",
    "    # Use tqdm for a progress bar over batches\n",
    "    pbar = tqdm(enumerate(batch_generator), total=steps_per_epoch, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "\n",
    "    # Loop over batches in the current epoch\n",
    "    for batch_idx, batch in pbar:\n",
    "        # Get RNG keys for the current step: one for PCD reset, one for the main step\n",
    "        train_key, pcd_reset_key, step_key = jax.random.split(train_key, 3)\n",
    "\n",
    "        # Execute one training step\n",
    "        tx_state, fantasy_particles, train_key, metrics = train_step(\n",
    "            tx_state,           # Current training state (params, opt_state)\n",
    "            batch,              # Current batch of data\n",
    "            fantasy_particles,  # Current fantasy particles\n",
    "            k,                  # Number of Gibbs steps\n",
    "            step_key,           # RNG key for this training step (used for Gibbs)\n",
    "            pcd_reset_key,      # RNG key specifically for potential PCD reset\n",
    "            batch_idx,          # Current batch index (for PCD reset condition)\n",
    "            pcd_reset,          # How often to reset PCD chain\n",
    "            temperature         # Sampling temperature\n",
    "        )\n",
    "\n",
    "        # Accumulate loss and update progress bar\n",
    "        batch_loss = metrics['loss']\n",
    "        total_epoch_loss += batch_loss\n",
    "        pbar.set_postfix(loss=f\"{batch_loss:.4f}\")\n",
    "\n",
    "    # Calculate average loss for the epoch\n",
    "    avg_epoch_loss = total_epoch_loss / steps_per_epoch\n",
    "    metrics_history['loss'].append(avg_epoch_loss)\n",
    "    epoch_time = time.time() - epoch_start_time\n",
    "\n",
    "    # Print epoch summary, including current learning rate\n",
    "    current_step = (epoch + 1) * steps_per_epoch\n",
    "    current_lr = lr_schedule(tx_state.step) # Optax schedules use step count from state\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] - Avg Loss: {avg_epoch_loss:.4f}, Current LR: {current_lr:.6f}, Time: {epoch_time:.2f}s\")\n",
    "\n",
    "\n",
    "print(\"Training finished.\")"
   ],
   "id": "51b588f48a146fb0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training steps: 18720\n",
      "Starting RBM training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/40: 100%|██████████| 468/468 [00:02<00:00, 156.95it/s, loss=-458.3484]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/40] - Avg Loss: -80.2311, Current LR: 0.000950, Time: 2.99s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/40: 100%|██████████| 468/468 [00:02<00:00, 203.18it/s, loss=-649.1641]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/40] - Avg Loss: -152.3282, Current LR: 0.000903, Time: 2.30s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/40: 100%|██████████| 468/468 [00:02<00:00, 202.92it/s, loss=-816.8418]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/40] - Avg Loss: -218.6608, Current LR: 0.000857, Time: 2.31s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/40: 100%|██████████| 468/468 [00:02<00:00, 195.38it/s, loss=-919.9186]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/40] - Avg Loss: -235.0880, Current LR: 0.000815, Time: 2.40s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/40: 100%|██████████| 468/468 [00:02<00:00, 214.36it/s, loss=-717.7847]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/40] - Avg Loss: -192.9754, Current LR: 0.000774, Time: 2.18s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/40: 100%|██████████| 468/468 [00:02<00:00, 192.43it/s, loss=-430.1732]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/40] - Avg Loss: -159.3421, Current LR: 0.000735, Time: 2.43s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/40: 100%|██████████| 468/468 [00:02<00:00, 193.23it/s, loss=-289.3395]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/40] - Avg Loss: -129.5526, Current LR: 0.000698, Time: 2.42s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/40: 100%|██████████| 468/468 [00:02<00:00, 215.22it/s, loss=-133.3070]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/40] - Avg Loss: -104.6099, Current LR: 0.000663, Time: 2.18s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/40: 100%|██████████| 468/468 [00:02<00:00, 205.87it/s, loss=-111.0704]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/40] - Avg Loss: -83.7010, Current LR: 0.000630, Time: 2.27s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/40: 100%|██████████| 468/468 [00:02<00:00, 207.70it/s, loss=-54.9473] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/40] - Avg Loss: -71.3379, Current LR: 0.000599, Time: 2.25s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/40:  19%|█▉        | 90/468 [00:00<00:02, 184.02it/s, loss=30.4053]  "
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Plotting Training Loss ---\n",
    "\n",
    "# Ensure the metrics_history dictionary and the 'loss' list exist\n",
    "# and contain the average loss values from each epoch of training.\n",
    "# Example structure: metrics_history = {'loss': [epoch1_loss, epoch2_loss, ...]}\n",
    "\n",
    "if 'metrics_history' in locals() and 'loss' in metrics_history and metrics_history['loss']:\n",
    "    num_epochs_trained = len(metrics_history['loss'])\n",
    "    epochs = range(1, num_epochs_trained + 1) # Epoch numbers for the x-axis (starting from 1)\n",
    "\n",
    "    plt.figure(figsize=(10, 6)) # Create a figure to draw on\n",
    "    plt.plot(epochs, metrics_history['loss'], marker='o', linestyle='-') # Plot epochs vs loss\n",
    "\n",
    "    # Add labels and title for clarity\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Average Loss (Free Energy Difference)\")\n",
    "    plt.title(\"RBM Training Loss per Epoch\")\n",
    "    plt.grid(True) # Add a grid\n",
    "\n",
    "    # Optional: Adjust x-axis ticks for better readability if many epochs\n",
    "    if num_epochs_trained > 10:\n",
    "        plt.xticks(range(0, num_epochs_trained + 1, max(1, num_epochs_trained // 10)))\n",
    "\n",
    "    plt.tight_layout() # Adjust layout\n",
    "    plt.show() # Display the generated plot\n",
    "\n",
    "else:\n",
    "    print(\"Unable to plot: 'metrics_history' dictionary or 'loss' list not found or empty.\")\n",
    "    print(\"Please ensure the training loop ran correctly and populated 'metrics_history['loss']'.\")"
   ],
   "id": "6bdff66a79d1eef3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "511f15b680068371"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
