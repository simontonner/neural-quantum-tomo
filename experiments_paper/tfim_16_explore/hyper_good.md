Starting Search (15 trials)...
#  |Btch|Hid|LR_0    |Std  |Nse |k |Time(s)|MinOv
---------------------------------------------------
1  |1024|128|1.6e-02 |0.03 |0.04|10|107.8  |0.99148
2  |4096|128|3.4e-02 |0.08 |0.02|5 |47.2   |0.95544
3  |2048|128|1.0e-02 |0.08 |0.04|10|88.7   |0.98803
4  |2048|64 |1.0e-02 |0.08 |0.08|10|60.0   |0.98993
5  |4096|64 |1.7e-02 |0.01 |0.04|20|76.6   |0.97365
6  |2048|80 |1.4e-02 |0.01 |0.08|10|75.9   |0.99119
7  |4096|80 |3.1e-02 |0.01 |0.08|20|114.1  |0.98926
8  |2048|128|8.2e-03 |0.08 |0.06|15|135.4  |0.99453
9  |2048|128|1.6e-02 |0.01 |0.06|5 |75.8   |0.95950
10 |1024|64 |1.3e-02 |0.01 |0.08|15|182.2  |0.99638
11 |4096|80 |1.1e-02 |0.08 |0.02|10|62.9   |0.99101
12 |2048|128|1.2e-02 |0.03 |0.04|5 |77.4   |0.96088
13 |1024|80 |3.3e-02 |0.01 |0.02|15|171.6  |0.99727
14 |1024|128|1.2e-02 |0.03 |0.04|5 |89.4   |0.95205
15 |1024|128|1.3e-02 |0.01 |0.02|20|192.4  |0.99689



-----


20k run

Running on: cpu
Refinement Dataset: 140000 samples.
# |Btch|Hid|LR    |k |Nse |Time |MinOv
--------------------------------------------------
1 |1024|80 |0.030 |14|0.02|215  |0.99426
2 |1024|112|0.030 |14|0.02|252  |0.99603
3 |1024|80 |0.035 |10|0.04|193  |0.98843
4 |512 |80 |0.020 |12|0.02|492  |0.99151
5 |1024|128|0.030 |12|0.02|228  |0.99469
6 |512 |128|0.034 |12|0.04|330  |0.98020
7 |1024|128|0.034 |14|0.02|258  |0.96087
8 |512 |80 |0.026 |14|0.04|466  |0.98581
9 |512 |100|0.028 |12|0.04|490  |0.98950
10|1024|80 |0.029 |14|0.02|391  |0.98992

Top 3 Configurations:
batch_size  n_hidden  lr_init  cd_k        time    min_ov
1        1024       112     0.03    14  251.972887  0.996028
4        1024       128     0.03    12  227.836784  0.994694
0        1024        80     0.03    14  214.532896  0.994258

Process finished with exit code 0

10k run

Running on: cpu
Dataset: 70000 samples (10k subset).

Starting 10k Sample Experiments (12 trials)...
# |Btch|Hid|LR    |k |Std  |Time |MinOv
-------------------------------------------------------
1 |1024|80 |0.033 |15|0.01 |180  |0.99632
2 |256 |80 |0.025 |5 |0.01 |180  |0.93578
3 |512 |100|0.030 |10|0.01 |217  |0.98397
4 |512 |80 |0.030 |10|0.01 |160  |0.99286
5 |512 |80 |0.030 |10|0.05 |148  |0.97277
6 |1024|80 |0.024 |10|0.01 |131  |0.98532
7 |256 |96 |0.025 |10|0.01 |257  |0.97884
8 |256 |112|0.021 |5 |0.02 |216  |0.95216
9 |256 |80 |0.036 |5 |0.01 |202  |0.95939
10|1024|112|0.034 |8 |0.01 |138  |0.97367
11|1024|80 |0.036 |8 |0.01 |114  |0.98603
12|1024|80 |0.032 |10|0.02 |119  |0.99213

Top 5 Configs (10k Samples):
batch_size  n_hidden   lr_init  cd_k  init_std        time    min_ov
0         1024        80  0.033000    15      0.01  179.935135  0.996316
3          512        80  0.030000    10      0.01  160.176576  0.992862
11        1024        80  0.032250    10      0.02  119.438080  0.992127
10        1024        80  0.036166     8      0.01  113.616171  0.986030
5         1024        80  0.023500    10      0.01  131.431363  0.985315

Process finished with exit code 0


------

# FINAL CONFIGURATION
final_config = {
'batch_size': 1024,       # The winner. Stable gradients, fast execution.
'n_hidden': 112,          # Squeezes out better accuracy than 80.
'cond_width': 64,         # Sufficient.
'lr_init': 0.03,          # Aggressive but stable with Batch 1024.
'lr_final': 1e-4,
'cd_k': 15,               # Essential for critical point accuracy.
'init_std': 0.01,         # Keep weights small at start.
'noise_frac': 0.02        # Just enough to prevent mode collapse.
}

# RECOMMENDED TRAINING STRATEGY
# 1. Use 50k - 100k samples per h-point (Total ~1M samples).
# 2. Train for 60-80 epochs.
# 3. This should take ~30-45 minutes and likely yield >0.997 overlap.


