{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-20T19:35:28.218966Z",
     "start_time": "2025-05-20T19:35:28.215390Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import json # If you decide to save/load theoretical expectations\n",
    "\n",
    "# --- Configuration (should match the data generation script) ---\n",
    "NUM_QUBITS = 6 # Or whatever NUM_QUBITS you used for data generation\n",
    "RNG_SEED = 42   # Same seed to regenerate the original W-state\n",
    "\n",
    "# --- Define Data Directory (where measurements are stored) ---\n",
    "DATA_DIR = Path(\"./w_aug_tomography_data\") # Must match previous notebook\n",
    "if not DATA_DIR.exists():\n",
    "    raise FileNotFoundError(f\"ERROR: Data directory {DATA_DIR.resolve()} not found!\")\n",
    "print(f\"Reading data from: {DATA_DIR.resolve()}\")\n",
    "\n",
    "# --- Initialize RNG for regenerating the original W-state ---\n",
    "rng_phases_original = np.random.default_rng(RNG_SEED)\n",
    "\n",
    "print(f\"Number of qubits for validation: {NUM_QUBITS}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data from: /Users/Tonni/Desktop/master-code/neural-quantum-tomo/case_studies/w_phase_augmented/w_aug_tomography_data\n",
      "Number of qubits for validation: 6\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T19:35:41.510967Z",
     "start_time": "2025-05-20T19:35:41.505407Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"Regenerating the original {NUM_QUBITS}-qubit phase-augmented W state...\")\n",
    "state_dim = 1 << NUM_QUBITS\n",
    "w_aug_original_true_state = np.zeros(state_dim, dtype=complex)\n",
    "thetas_original = rng_phases_original.uniform(0, 2 * np.pi, size=NUM_QUBITS)\n",
    "for k in range(NUM_QUBITS):\n",
    "    idx = 1 << (NUM_QUBITS - 1 - k)\n",
    "    w_aug_original_true_state[idx] = np.exp(1j * thetas_original[k]) / np.sqrt(NUM_QUBITS)\n",
    "print(f\"Original W state norm: {np.linalg.norm(w_aug_original_true_state):.6f}\")"
   ],
   "id": "4b7bc8275165bda",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regenerating the original 6-qubit phase-augmented W state...\n",
      "Original W state norm: 1.000000\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T19:36:15.684401Z",
     "start_time": "2025-05-20T19:36:15.670853Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define Pauli matrices (useful for theoretical calculations)\n",
    "sigma_i = np.array([[1, 0], [0, 1]], dtype=complex)\n",
    "sigma_x = np.array([[0, 1], [1, 0]], dtype=complex)\n",
    "sigma_y = np.array([[0, -1j], [1j, 0]], dtype=complex)\n",
    "sigma_z = np.array([[1, 0], [0, -1]], dtype=complex)\n",
    "pauli_ops = {'I': sigma_i, 'X': sigma_x, 'Y': sigma_y, 'Z': sigma_z}\n",
    "\n",
    "all_measurement_bases_strings = []\n",
    "# ... (same code as before to populate all_measurement_bases_strings) ...\n",
    "amplitude_basis_str = 'Z' * NUM_QUBITS\n",
    "all_measurement_bases_strings.append(amplitude_basis_str)\n",
    "for i in range(NUM_QUBITS - 1):\n",
    "    basis_list = ['Z'] * NUM_QUBITS; basis_list[i] = 'X'; basis_list[i+1] = 'X'\n",
    "    all_measurement_bases_strings.append(\"\".join(basis_list))\n",
    "for i in range(NUM_QUBITS - 1):\n",
    "    basis_list = ['Z'] * NUM_QUBITS; basis_list[i] = 'X'; basis_list[i+1] = 'Y'\n",
    "    all_measurement_bases_strings.append(\"\".join(basis_list))\n",
    "\n",
    "\n",
    "# Infer NUM_SAMPLES_PER_BASIS (same logic as before)\n",
    "num_samples_inferred = None\n",
    "# ... (same inference logic) ...\n",
    "if num_samples_inferred is None: # Fallback if inference fails\n",
    "    print(\"Warning: Could not infer num_samples. Using a default of 20.\")\n",
    "    num_samples_inferred = 20\n",
    "\n",
    "\n",
    "# Store parsed data: {basis_string: list_of_numerical_eigenvalue_tuples}\n",
    "# Each tuple will be (-1, 1, 1, -1, ...) corresponding to eigenvalues\n",
    "parsed_datasets = {}\n",
    "\n",
    "print(\"\\n--- Ingesting and Parsing Measurement Data ---\")\n",
    "for basis_str in all_measurement_bases_strings:\n",
    "    filename = DATA_DIR / f\"w_aug_{basis_str}_{num_samples_inferred}.txt\"\n",
    "    dataset_for_basis_eigenvalues = []\n",
    "    if filename.exists():\n",
    "        # print(f\"Reading data for basis: {basis_str} from {filename.name}\")\n",
    "        with open(filename, 'r') as f_in:\n",
    "            for line_num, line in enumerate(f_in):\n",
    "                measurement_char_str = line.strip()\n",
    "                if len(measurement_char_str) != NUM_QUBITS:\n",
    "                    print(f\"Warning: Line {line_num+1} in {filename.name} has wrong length: '{measurement_char_str}'\")\n",
    "                    continue\n",
    "\n",
    "                eigenvalues_for_sample = []\n",
    "                valid_sample = True\n",
    "                for char_idx, measured_char in enumerate(measurement_char_str):\n",
    "                    # pauli_measured_on_qubit = basis_str[char_idx] # This is the *intended* measurement\n",
    "                    # The character itself tells us the Pauli and outcome\n",
    "                    if measured_char.islower(): # -1 eigenvalue\n",
    "                        eigenvalues_for_sample.append(-1)\n",
    "                    elif measured_char.isupper(): # +1 eigenvalue\n",
    "                        eigenvalues_for_sample.append(1)\n",
    "                    else:\n",
    "                        print(f\"Warning: Invalid char '{measured_char}' in {filename.name}, line {line_num+1}\")\n",
    "                        valid_sample = False\n",
    "                        break\n",
    "                if valid_sample:\n",
    "                    dataset_for_basis_eigenvalues.append(tuple(eigenvalues_for_sample))\n",
    "\n",
    "        parsed_datasets[basis_str] = dataset_for_basis_eigenvalues\n",
    "        # print(f\"  Read and parsed {len(dataset_for_basis_eigenvalues)} samples.\")\n",
    "    else:\n",
    "        print(f\"Warning: Measurement file not found for basis {basis_str}: {filename}\")\n",
    "\n",
    "if not parsed_datasets:\n",
    "    raise RuntimeError(\"ERROR: No measurement data was loaded. Cannot proceed.\")\n",
    "\n",
    "print(\"\\n--- Data Ingestion and Parsing Complete ---\")\n",
    "print(f\"Loaded data for {len(parsed_datasets)} bases.\")\n",
    "# Example:\n",
    "# if amplitude_basis_str in parsed_datasets:\n",
    "#     print(f\"First 5 parsed samples for ZZZ basis: {parsed_datasets[amplitude_basis_str][:5]}\")"
   ],
   "id": "92661410c320e934",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Could not infer num_samples. Using a default of 20.\n",
      "\n",
      "--- Ingesting and Parsing Measurement Data ---\n",
      "\n",
      "--- Data Ingestion and Parsing Complete ---\n",
      "Loaded data for 11 bases.\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T19:36:32.648368Z",
     "start_time": "2025-05-20T19:36:32.640092Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"\\n--- Validation 1: Z-Basis Probability Distribution ---\")\n",
    "z_basis_key = 'Z' * NUM_QUBITS\n",
    "if z_basis_key in parsed_datasets:\n",
    "    z_eigenvalue_samples = parsed_datasets[z_basis_key] # List of tuples like (1,-1,1,...)\n",
    "\n",
    "    # Convert eigenvalue tuples to binary strings (0 for +1, 1 for -1)\n",
    "    # This mapping is crucial for comparing with |<binary_string | Psi>|^2\n",
    "    # If +1 eigenvalue of sigma_Z is state |0> and -1 is state |1>\n",
    "    z_binary_outcomes = []\n",
    "    for eigen_tuple in z_eigenvalue_samples:\n",
    "        binary_string = \"\".join(['0' if e == 1 else '1' for e in eigen_tuple])\n",
    "        z_binary_outcomes.append(binary_string)\n",
    "\n",
    "    empirical_counts = Counter(z_binary_outcomes)\n",
    "    total_z_samples = len(z_binary_outcomes)\n",
    "\n",
    "    print(f\"Empirical probabilities from {total_z_samples} Z-basis samples:\")\n",
    "    empirical_probs = {outcome: count / total_z_samples for outcome, count in empirical_counts.items()}\n",
    "\n",
    "    # Calculate theoretical probabilities from w_aug_original_true_state\n",
    "    theoretical_probs_z = {}\n",
    "    for i in range(state_dim):\n",
    "        binary_string = format(i, f'0{NUM_QUBITS}b') # int to binary string, e.g., 0 -> \"000\", 1 -> \"001\"\n",
    "        # This assumes computational basis |000>, |001>, ...\n",
    "        # matches our binary string interpretation.\n",
    "        prob = np.abs(w_aug_original_true_state[i])**2\n",
    "        if prob > 1e-9: # Only store non-negligible probabilities\n",
    "            theoretical_probs_z[binary_string] = prob\n",
    "\n",
    "    print(\"\\nComparison (Empirical vs Theoretical):\")\n",
    "    all_outcomes = sorted(list(set(empirical_probs.keys()) | set(theoretical_probs_z.keys())))\n",
    "\n",
    "    max_empirical_dev = 0\n",
    "    total_squared_error = 0\n",
    "\n",
    "    for outcome_str in all_outcomes:\n",
    "        emp_p = empirical_probs.get(outcome_str, 0.0)\n",
    "        the_p = theoretical_probs_z.get(outcome_str, 0.0)\n",
    "\n",
    "        # W-state components are those with a single '1' (if 0 means +1 Z-eigenstate |0>)\n",
    "        # or single '0' (if 1 means +1 Z-eigenstate |0>)\n",
    "        # Our W-state has |100...>, |010...>, etc.\n",
    "        # binary_string: '0' means sigma_Z = +1 (state |0>), '1' means sigma_Z = -1 (state |1>)\n",
    "        # So, W-state \"single excitation\" |...1...> (where |1> is sigma_Z = -1)\n",
    "        # corresponds to binary strings with a single '1'.\n",
    "        is_w_like = (outcome_str.count('1') == 1)\n",
    "\n",
    "        if emp_p > 0 or the_p > 1e-7: # Print if either is significant\n",
    "            print(f\"  Outcome {outcome_str} (W-like: {is_w_like}): Emp_Prob={emp_p:.4f}, Theory_Prob={the_p:.4f}, Diff={emp_p-the_p:+.4f}\")\n",
    "            if abs(emp_p - the_p) > max_empirical_dev:\n",
    "                max_empirical_dev = abs(emp_p - the_p)\n",
    "            total_squared_error += (emp_p - the_p)**2\n",
    "\n",
    "    print(f\"\\nMax absolute deviation in Z-probabilities: {max_empirical_dev:.4f}\")\n",
    "    print(f\"Mean Squared Error in Z-probabilities: {total_squared_error/len(all_outcomes):.6f}\")\n",
    "\n",
    "    # Chi-squared test could also be used if counts are high enough\n",
    "else:\n",
    "    print(f\"Data for Z-basis '{z_basis_key}' not found.\")"
   ],
   "id": "f19c16168b09121",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Validation 1: Z-Basis Probability Distribution ---\n",
      "Empirical probabilities from 20 Z-basis samples:\n",
      "\n",
      "Comparison (Empirical vs Theoretical):\n",
      "  Outcome 000001 (W-like: True): Emp_Prob=0.0500, Theory_Prob=0.1667, Diff=-0.1167\n",
      "  Outcome 000010 (W-like: True): Emp_Prob=0.1500, Theory_Prob=0.1667, Diff=-0.0167\n",
      "  Outcome 000100 (W-like: True): Emp_Prob=0.1500, Theory_Prob=0.1667, Diff=-0.0167\n",
      "  Outcome 001000 (W-like: True): Emp_Prob=0.1000, Theory_Prob=0.1667, Diff=-0.0667\n",
      "  Outcome 010000 (W-like: True): Emp_Prob=0.2500, Theory_Prob=0.1667, Diff=+0.0833\n",
      "  Outcome 100000 (W-like: True): Emp_Prob=0.3000, Theory_Prob=0.1667, Diff=+0.1333\n",
      "\n",
      "Max absolute deviation in Z-probabilities: 0.1333\n",
      "Mean Squared Error in Z-probabilities: 0.007222\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T19:37:12.651399Z",
     "start_time": "2025-05-20T19:37:12.601808Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_operator_for_qubit(pauli_char, qubit_idx, total_qubits):\n",
    "    \"\"\"Helper to construct N-qubit operator for a single Pauli on one qubit.\"\"\"\n",
    "    op_list = [sigma_i] * total_qubits\n",
    "    if pauli_char == 'X': op_list[qubit_idx] = sigma_x\n",
    "    elif pauli_char == 'Y': op_list[qubit_idx] = sigma_y\n",
    "    elif pauli_char == 'Z': op_list[qubit_idx] = sigma_z\n",
    "    else: raise ValueError(f\"Unknown Pauli char: {pauli_char}\")\n",
    "\n",
    "    full_op = op_list[0]\n",
    "    for i in range(1, total_qubits):\n",
    "        full_op = np.kron(full_op, op_list[i])\n",
    "    return full_op\n",
    "\n",
    "def get_two_qubit_operator(p1_char, q1_idx, p2_char, q2_idx, total_qubits):\n",
    "    \"\"\"Helper for N-qubit operator for two Paulis on two qubits.\"\"\"\n",
    "    op_list = [sigma_i] * total_qubits\n",
    "    # Set first Pauli\n",
    "    if p1_char == 'X': op_list[q1_idx] = sigma_x\n",
    "    elif p1_char == 'Y': op_list[q1_idx] = sigma_y\n",
    "    elif p1_char == 'Z': op_list[q1_idx] = sigma_z\n",
    "    # Set second Pauli\n",
    "    if p2_char == 'X': op_list[q2_idx] = sigma_x\n",
    "    elif p2_char == 'Y': op_list[q2_idx] = sigma_y\n",
    "    elif p2_char == 'Z': op_list[q2_idx] = sigma_z\n",
    "\n",
    "    full_op = op_list[0]\n",
    "    for i in range(1, total_qubits):\n",
    "        full_op = np.kron(full_op, op_list[i])\n",
    "    return full_op\n",
    "\n",
    "print(\"\\n--- Validation 2: Two-Qubit Correlators ---\")\n",
    "\n",
    "correlator_bases_to_check = []\n",
    "if NUM_QUBITS >= 2:\n",
    "    # XX on (0,1), rest Z\n",
    "    b_xx = ['Z'] * NUM_QUBITS; b_xx[0] = 'X'; b_xx[1] = 'X'; correlator_bases_to_check.append(\"\".join(b_xx))\n",
    "    # XY on (0,1), rest Z\n",
    "    b_xy = ['Z'] * NUM_QUBITS; b_xy[0] = 'X'; b_xy[1] = 'Y'; correlator_bases_to_check.append(\"\".join(b_xy))\n",
    "    # Add more if desired, e.g., YX, YY, XZ, ZX, etc. on different qubit pairs\n",
    "\n",
    "for basis_str in correlator_bases_to_check:\n",
    "    if basis_str in parsed_datasets:\n",
    "        eigenvalue_samples = parsed_datasets[basis_str] # List of tuples like (1,-1,1,...)\n",
    "        if not eigenvalue_samples:\n",
    "            print(f\"No samples for basis {basis_str}, skipping correlator.\")\n",
    "            continue\n",
    "\n",
    "        # Identify the two non-Z qubits and their Pauli ops\n",
    "        # This is simplified for our specific basis generation.\n",
    "        # A more general approach would parse the basis_str fully.\n",
    "        q_indices_measured = []\n",
    "        paulis_measured = []\n",
    "        for i, p_char in enumerate(basis_str):\n",
    "            if p_char != 'Z':\n",
    "                q_indices_measured.append(i)\n",
    "                paulis_measured.append(p_char)\n",
    "\n",
    "        if len(q_indices_measured) != 2: # Should be 2 for our XX, XY correlator bases\n",
    "            print(f\"Warning: Basis {basis_str} does not seem to be a two-qubit correlator basis as expected.\")\n",
    "            continue\n",
    "\n",
    "        q0_idx, q1_idx = q_indices_measured[0], q_indices_measured[1]\n",
    "        p0_char, p1_char = paulis_measured[0], paulis_measured[1]\n",
    "\n",
    "        # Empirical correlator: product of eigenvalues for q0_idx, q1_idx, averaged\n",
    "        empirical_correlator_values = []\n",
    "        for sample_eigenvalues in eigenvalue_samples:\n",
    "            # Eigenvalues in the sample correspond to the order of qubits\n",
    "            val_q0 = sample_eigenvalues[q0_idx]\n",
    "            val_q1 = sample_eigenvalues[q1_idx]\n",
    "            empirical_correlator_values.append(val_q0 * val_q1)\n",
    "\n",
    "        empirical_mean_corr = np.mean(empirical_correlator_values)\n",
    "        empirical_std_err_corr = np.std(empirical_correlator_values) / np.sqrt(len(empirical_correlator_values))\n",
    "\n",
    "        # Theoretical correlator\n",
    "        # This is <Psi_W | Op_q0 * Op_q1 * (Product_k Z_k for Z-measured qubits) | Psi_W>\n",
    "        # For W-state, only terms where Z-measured qubits are in |0> (eigenvalue +1) contribute significantly\n",
    "        # if the W-state components are |...1...>.\n",
    "        # For the W state |Psi_W> = sum_k c_k |phi_k> where |phi_k> are comp. basis states.\n",
    "        # <P0_idx0 P1_idx1> can be tricky because the measurement basis also has Zs.\n",
    "        # The paper implies that their basis choice simplifies this for phase extraction.\n",
    "        # For a pure state |Psi>, <A> = <Psi| A |Psi>.\n",
    "        # The correlator we are estimating from this basis is <P_q0 P_q1>\n",
    "        # where P_q0 is Pauli on q0, P_q1 on q1, AND other qubits k are implicitly\n",
    "        # projected onto the Z-eigenstates that are consistent with the W-state structure.\n",
    "        #\n",
    "        # A simpler theoretical value to compare against is the direct expectation value\n",
    "        # of the two-qubit Pauli product operator on the *full* W-state.\n",
    "        op_to_measure = get_two_qubit_operator(p0_char, q0_idx, p1_char, q1_idx, NUM_QUBITS)\n",
    "        theoretical_corr = np.vdot(w_aug_original_true_state, op_to_measure @ w_aug_original_true_state).real\n",
    "        # .real because expectation of Hermitian op is real. Small imag part due to numerics.\n",
    "\n",
    "        print(f\"\\nCorrelator for basis {basis_str} (measuring {p0_char}{q0_idx} {p1_char}{q1_idx}):\")\n",
    "        print(f\"  Empirical: {empirical_mean_corr:.4f} +/- {empirical_std_err_corr:.4f} (from {len(eigenvalue_samples)} samples)\")\n",
    "        print(f\"  Theoretical <{p0_char}{q0_idx} {p1_char}{q1_idx}>: {theoretical_corr:.4f}\")\n",
    "        print(f\"  Difference: {empirical_mean_corr - theoretical_corr:+.4f}\")\n",
    "\n",
    "    else:\n",
    "        print(f\"Data for correlator basis {basis_str} not found.\")"
   ],
   "id": "179622161b41bfc7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Validation 2: Two-Qubit Correlators ---\n",
      "\n",
      "Correlator for basis XXZZZZ (measuring X0 X1):\n",
      "  Empirical: 0.0000 +/- 0.2236 (from 20 samples)\n",
      "  Theoretical <X0 X1>: 0.3293\n",
      "  Difference: -0.3293\n",
      "\n",
      "Correlator for basis XYZZZZ (measuring X0 Y1):\n",
      "  Empirical: 0.3000 +/- 0.2133 (from 20 samples)\n",
      "  Theoretical <X0 Y1>: 0.0520\n",
      "  Difference: +0.2480\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "da3499ee3037ae4d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
