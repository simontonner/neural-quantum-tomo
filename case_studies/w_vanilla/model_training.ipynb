{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T12:04:12.361266Z",
     "start_time": "2025-05-06T12:04:12.358019Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add parent directory (case_studies/) to sys.path to discover restricted_boltzmann_machine\n",
    "sys.path.append(str(Path.cwd().parent))"
   ],
   "id": "b2f9d6c305a83c8f",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T12:04:13.983017Z",
     "start_time": "2025-05-06T12:04:13.881828Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "import pickle, itertools, math, collections\n",
    "import numpy as np\n",
    "import jax, jax.numpy as jnp\n",
    "import optax\n",
    "from jax.random import PRNGKey\n",
    "\n",
    "from rbm.rbm import RBM\n",
    "from rbm.pcd_trainer import RBMTrainState, train_rbm\n",
    "from rbm.cosine_annealing_sampler import get_cosine_schedule\n",
    "\n",
    "DATA_DIR   = Path(\"./data\")\n",
    "MODELS_DIR = Path(\"./models\"); MODELS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "FILE = DATA_DIR / \"w_vanilla_20_20000.txt\"\n",
    "assert FILE.exists(), f\"{FILE} missing – run the generator first.\"\n",
    "\n",
    "print(\"JAX devices:\", jax.devices())"
   ],
   "id": "ef74da6593730de0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JAX devices: [CpuDevice(id=0)]\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T12:04:26.085065Z",
     "start_time": "2025-05-06T12:04:26.027253Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- helper to map 'Z','z'  -> 1,0 -------------------------------------------\n",
    "def to_binary(line: str) -> np.ndarray:\n",
    "    return np.fromiter((c == \"Z\" for c in line.strip()), dtype=np.float32, count=20)\n",
    "\n",
    "with open(FILE) as f:\n",
    "    data = np.stack([to_binary(l) for l in f])\n",
    "\n",
    "N_TOTAL, N_VIS = data.shape\n",
    "print(f\"Loaded {N_TOTAL} samples of length {N_VIS}.\")\n",
    "\n",
    "# quick inspection: show first 5 strings and site-occupancy histogram ----------\n",
    "print(\"First 5 samples (as 0/1 arrays):\\n\", data[:5])\n",
    "\n",
    "occ = data.sum(0)            # how often each spin is 'up'\n",
    "print(\"Site-occupancy counts (should all be ≈ N_TOTAL / N_VIS):\")\n",
    "print(occ.astype(int))"
   ],
   "id": "eec9662091285f51",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 20000 samples of length 20.\n",
      "First 5 samples (as 0/1 arrays):\n",
      " [[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "Site-occupancy counts (should all be ≈ N_TOTAL / N_VIS):\n",
      "[ 975  989 1003 1021  991 1017  997  985 1021 1005  998 1000  989 1029\n",
      "  985  965 1026 1030  972 1002]\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T12:07:31.881861Z",
     "start_time": "2025-05-06T12:07:31.878378Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def make_loader(arr: np.ndarray, batch_size: int, rng_key):\n",
    "    \"\"\"Yield shuffled mini‐batches of shape (batch_size, N_VIS) as (data, None).\"\"\"\n",
    "    idx = jax.random.permutation(rng_key, len(arr))\n",
    "    arr = arr[idx]\n",
    "    for i in range(0, len(arr), batch_size):\n",
    "        batch = arr[i:i+batch_size]\n",
    "        yield (batch, None)"
   ],
   "id": "af2bfbabf43764c3",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T12:07:34.902706Z",
     "start_time": "2025-05-06T12:07:34.894969Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ----- global hyper-parameters ------------------------------------------------\n",
    "N_HID        = 20          # M = N\n",
    "K_STEPS      = 1           # PCD-1\n",
    "BATCH_SIZE   = 128\n",
    "LR           = 1e-3\n",
    "N_EPOCHS     = 40\n",
    "PCD_RESET    = 75\n",
    "WEIGHT_DECAY = 1e-5\n",
    "LR_DECAY     = 0.95\n",
    "\n",
    "def train_rbm_subset(subset_size: int, rng_key):\n",
    "    \"\"\"Return (state, rng_key) after training on a random subset.\"\"\"\n",
    "    sk1, sk2 = jax.random.split(rng_key)\n",
    "    subset   = jax.random.choice(sk1, data, (subset_size,), replace=False)\n",
    "    loader   = list(make_loader(subset, BATCH_SIZE, sk2))\n",
    "\n",
    "    # ---- scheduler & optimiser\n",
    "    lr_sched = optax.exponential_decay(LR, len(loader),\n",
    "                                       decay_rate=LR_DECAY, staircase=True)\n",
    "\n",
    "    # optax.adam() has no weight_decay kwarg → apply L2 via add_decayed_weights\n",
    "    opt      = optax.chain(\n",
    "        optax.add_decayed_weights(WEIGHT_DECAY),\n",
    "        optax.adam(lr_sched)\n",
    "    )\n",
    "\n",
    "    rbm      = RBM(n_visible=N_VIS, n_hidden=N_HID, k=K_STEPS)\n",
    "    dummy    = jnp.ones((BATCH_SIZE, N_VIS), dtype=jnp.float32)\n",
    "    rng_key, sk = jax.random.split(rng_key)\n",
    "    v_pers   = jax.random.bernoulli(sk, 0.5, shape=dummy.shape).astype(jnp.float32)\n",
    "    params   = rbm.init(rng_key, dummy, v_pers, rng_key)[\"params\"]\n",
    "\n",
    "    state    = RBMTrainState.create(apply_fn=rbm.apply, params=params, tx=opt)\n",
    "\n",
    "    state, metrics, rng_key = train_rbm(state,\n",
    "                                        loader,\n",
    "                                        N_EPOCHS,\n",
    "                                        rng_key,\n",
    "                                        pcd_reset=PCD_RESET,\n",
    "                                        scheduler=lr_sched)\n",
    "    return state, rng_key"
   ],
   "id": "a1da3bf65493ee2c",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T12:07:40.840428Z",
     "start_time": "2025-05-06T12:07:37.808308Z"
    }
   },
   "cell_type": "code",
   "source": [
    "rng = PRNGKey(0)\n",
    "\n",
    "states = {}\n",
    "for ns in (50, 1_000, 20_000):\n",
    "    print(f\"\\n=== Training on N_s = {ns} ===\")\n",
    "    state, rng = train_rbm_subset(ns, rng)\n",
    "    states[ns] = state\n",
    "print(\"\\nFinished all trainings.\")"
   ],
   "id": "10ec35d18de9eb4d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training on N_s = 50 ===\n",
      "Epoch [1/40] – FE-loss: 0.0196\n",
      "Epoch [2/40] – FE-loss: -0.0958\n",
      "Epoch [3/40] – FE-loss: -0.1614\n",
      "Epoch [4/40] – FE-loss: -0.2887\n",
      "Epoch [5/40] – FE-loss: -0.3620\n",
      "Epoch [6/40] – FE-loss: -0.4129\n",
      "Epoch [7/40] – FE-loss: -0.5079\n",
      "Epoch [8/40] – FE-loss: -0.5443\n",
      "Epoch [9/40] – FE-loss: -0.6414\n",
      "Epoch [10/40] – FE-loss: -0.6745\n",
      "Epoch [11/40] – FE-loss: -0.7724\n",
      "Epoch [12/40] – FE-loss: -0.8179\n",
      "Epoch [13/40] – FE-loss: -0.7842\n",
      "Epoch [14/40] – FE-loss: -0.8428\n",
      "Epoch [15/40] – FE-loss: -0.8816\n",
      "Epoch [16/40] – FE-loss: -1.0139\n",
      "Epoch [17/40] – FE-loss: -1.0035\n",
      "Epoch [18/40] – FE-loss: -0.9721\n",
      "Epoch [19/40] – FE-loss: -1.0556\n",
      "Epoch [20/40] – FE-loss: -1.1099\n",
      "Epoch [21/40] – FE-loss: -1.0768\n",
      "Epoch [22/40] – FE-loss: -1.1358\n",
      "Epoch [23/40] – FE-loss: -1.1823\n",
      "Epoch [24/40] – FE-loss: -1.2042\n",
      "Epoch [25/40] – FE-loss: -1.2695\n",
      "Epoch [26/40] – FE-loss: -1.2569\n",
      "Epoch [27/40] – FE-loss: -1.2001\n",
      "Epoch [28/40] – FE-loss: -1.2535\n",
      "Epoch [29/40] – FE-loss: -1.2973\n",
      "Epoch [30/40] – FE-loss: -1.3845\n",
      "Epoch [31/40] – FE-loss: -1.2379\n",
      "Epoch [32/40] – FE-loss: -1.3950\n",
      "Epoch [33/40] – FE-loss: -1.4144\n",
      "Epoch [34/40] – FE-loss: -1.4470\n",
      "Epoch [35/40] – FE-loss: -1.2726\n",
      "Epoch [36/40] – FE-loss: -1.3963\n",
      "Epoch [37/40] – FE-loss: -1.4518\n",
      "Epoch [38/40] – FE-loss: -1.3721\n",
      "Epoch [39/40] – FE-loss: -1.4108\n",
      "Epoch [40/40] – FE-loss: -1.4195\n",
      "\n",
      "=== Training on N_s = 1000 ===\n",
      "Epoch [1/40] – FE-loss: -0.2952\n",
      "Epoch [2/40] – FE-loss: -0.9839\n",
      "Epoch [3/40] – FE-loss: -1.5240\n",
      "Epoch [4/40] – FE-loss: -2.0274\n",
      "Epoch [5/40] – FE-loss: -2.3970\n",
      "Epoch [6/40] – FE-loss: -2.7360\n",
      "Epoch [7/40] – FE-loss: -3.0270\n",
      "Epoch [8/40] – FE-loss: -3.2754\n",
      "Epoch [9/40] – FE-loss: -3.4885\n",
      "Epoch [10/40] – FE-loss: -3.5826\n",
      "Epoch [11/40] – FE-loss: -3.7621\n",
      "Epoch [12/40] – FE-loss: -3.9321\n",
      "Epoch [13/40] – FE-loss: -4.1235\n",
      "Epoch [14/40] – FE-loss: -4.1464\n",
      "Epoch [15/40] – FE-loss: -4.3133\n",
      "Epoch [16/40] – FE-loss: -4.3666\n",
      "Epoch [17/40] – FE-loss: -4.5223\n",
      "Epoch [18/40] – FE-loss: -4.4632\n",
      "Epoch [19/40] – FE-loss: -4.5850\n",
      "Epoch [20/40] – FE-loss: -4.5250\n",
      "Epoch [21/40] – FE-loss: -4.6649\n",
      "Epoch [22/40] – FE-loss: -4.7224\n",
      "Epoch [23/40] – FE-loss: -4.6989\n",
      "Epoch [24/40] – FE-loss: -4.6714\n",
      "Epoch [25/40] – FE-loss: -4.7987\n",
      "Epoch [26/40] – FE-loss: -4.7330\n",
      "Epoch [27/40] – FE-loss: -4.7839\n",
      "Epoch [28/40] – FE-loss: -4.8786\n",
      "Epoch [29/40] – FE-loss: -5.0731\n",
      "Epoch [30/40] – FE-loss: -4.8769\n",
      "Epoch [31/40] – FE-loss: -5.0342\n",
      "Epoch [32/40] – FE-loss: -4.9173\n",
      "Epoch [33/40] – FE-loss: -4.8918\n",
      "Epoch [34/40] – FE-loss: -4.9435\n",
      "Epoch [35/40] – FE-loss: -4.9972\n",
      "Epoch [36/40] – FE-loss: -5.1008\n",
      "Epoch [37/40] – FE-loss: -5.0145\n",
      "Epoch [38/40] – FE-loss: -5.0371\n",
      "Epoch [39/40] – FE-loss: -5.0639\n",
      "Epoch [40/40] – FE-loss: -5.1336\n",
      "\n",
      "=== Training on N_s = 20000 ===\n",
      "Epoch [1/40] – FE-loss: -3.6130\n",
      "Epoch [2/40] – FE-loss: -4.3588\n",
      "Epoch [3/40] – FE-loss: -2.5639\n",
      "Epoch [4/40] – FE-loss: -1.3185\n",
      "Epoch [5/40] – FE-loss: -0.6835\n",
      "Epoch [6/40] – FE-loss: -0.4349\n",
      "Epoch [7/40] – FE-loss: -0.3363\n",
      "Epoch [8/40] – FE-loss: -0.2494\n",
      "Epoch [9/40] – FE-loss: -0.2475\n",
      "Epoch [10/40] – FE-loss: -0.2587\n",
      "Epoch [11/40] – FE-loss: -0.2099\n",
      "Epoch [12/40] – FE-loss: -0.2253\n",
      "Epoch [13/40] – FE-loss: -0.1943\n",
      "Epoch [14/40] – FE-loss: -0.2400\n",
      "Epoch [15/40] – FE-loss: -0.2146\n",
      "Epoch [16/40] – FE-loss: -0.1637\n",
      "Epoch [17/40] – FE-loss: -0.2065\n",
      "Epoch [18/40] – FE-loss: -0.1919\n",
      "Epoch [19/40] – FE-loss: -0.1913\n",
      "Epoch [20/40] – FE-loss: -0.1794\n",
      "Epoch [21/40] – FE-loss: -0.1915\n",
      "Epoch [22/40] – FE-loss: -0.1565\n",
      "Epoch [23/40] – FE-loss: -0.1734\n",
      "Epoch [24/40] – FE-loss: -0.1481\n",
      "Epoch [25/40] – FE-loss: -0.1694\n",
      "Epoch [26/40] – FE-loss: -0.1564\n",
      "Epoch [27/40] – FE-loss: -0.1924\n",
      "Epoch [28/40] – FE-loss: -0.1058\n",
      "Epoch [29/40] – FE-loss: -0.1759\n",
      "Epoch [30/40] – FE-loss: -0.1392\n",
      "Epoch [31/40] – FE-loss: -0.0969\n",
      "Epoch [32/40] – FE-loss: -0.1389\n",
      "Epoch [33/40] – FE-loss: -0.1442\n",
      "Epoch [34/40] – FE-loss: -0.1553\n",
      "Epoch [35/40] – FE-loss: -0.1503\n",
      "Epoch [36/40] – FE-loss: -0.1016\n",
      "Epoch [37/40] – FE-loss: -0.1243\n",
      "Epoch [38/40] – FE-loss: -0.1046\n",
      "Epoch [39/40] – FE-loss: -0.1476\n",
      "Epoch [40/40] – FE-loss: -0.1386\n",
      "\n",
      "Finished all trainings.\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T12:08:13.395402Z",
     "start_time": "2025-05-06T12:08:13.390245Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def save_state(state, subset_size: int):\n",
    "    name = f\"rbm_w_vanilla_20_{subset_size}.pkl\"\n",
    "    path = MODELS_DIR / name\n",
    "    with open(path, \"wb\") as f:\n",
    "        pickle.dump({\"params\": state.params,\n",
    "                     \"visible\": N_VIS,\n",
    "                     \"hidden\": N_HID}, f)\n",
    "    print(\"✓ saved\", path)\n",
    "\n",
    "for ns, st in states.items():\n",
    "    save_state(st, ns)"
   ],
   "id": "c9594025c0bb9896",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ saved models/rbm_w_vanilla_20_50.pkl\n",
      "✓ saved models/rbm_w_vanilla_20_1000.pkl\n",
      "✓ saved models/rbm_w_vanilla_20_20000.pkl\n"
     ]
    }
   ],
   "execution_count": 13
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
